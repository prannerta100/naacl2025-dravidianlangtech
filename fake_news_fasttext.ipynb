{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification"
      ],
      "metadata": {
        "id": "-JVQu0aQqOQ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HILQHui1xZOs",
        "outputId": "ce1f2a03-bcd7-415b-ff6c-e32feb484825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Macro F1 Score: 0.9957\n",
            "Test Macro F1 Score: 0.8050\n"
          ]
        }
      ],
      "source": [
        "!pip install -q fasttext\n",
        "import pandas as pd\n",
        "import fasttext\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv('Fake_train.csv')\n",
        "test_df = pd.read_csv('fake_test_binary_with_labels.csv')\n",
        "\n",
        "\n",
        "\n",
        "# Prepare the data (fastText expects labels to start with '__label__' prefix)\n",
        "def preprocess_for_fasttext(df, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        for _, row in df.iterrows():\n",
        "            # fastText expects the label to be in the form '__label__<label>'\n",
        "            f.write(f\"__label__{row['label']} {row['text']}\\n\")\n",
        "\n",
        "# Preprocess and save data in fastText's format\n",
        "preprocess_for_fasttext(train_df, 'train.ft')\n",
        "preprocess_for_fasttext(test_df, 'test.ft')\n",
        "\n",
        "# Train a fastText classifier\n",
        "model = fasttext.train_supervised(input='train.ft', epoch=10, lr=0.1, neg=5, loss='hs')\n",
        "                                  # epoch=10,          # Reduce number of epochs to prevent overfitting\n",
        "                                  # lr=0.05,           # Lower learning rate for more gradual learning\n",
        "                                  # dim=50,            # Reduce dimension of word vectors (default is 100)\n",
        "                                  # wordNgrams=1,      # Reduce the size of word n-grams (use 1 for unigrams)\n",
        "                                  # neg=5,             # Use negative sampling to improve generalization\n",
        "                                  # loss='hs',         # Use hierarchical softmax (faster and often better for smaller datasets)\n",
        "                                  # thread=4)          # Use multiple threads for faster training\n",
        "\n",
        "\n",
        "# Make predictions on train and test data\n",
        "def predict_fasttext(model, df):\n",
        "    predictions = []\n",
        "    for _, row in df.iterrows():\n",
        "        # Predict the label for the text using the trained model\n",
        "        labels, _ = model.predict(row['text'])  # fastText outputs tuple (labels, probabilities)\n",
        "        predictions.append(labels[0].replace('__label__', ''))  # Get the first label and remove the prefix\n",
        "    return predictions\n",
        "\n",
        "y_train_pred = predict_fasttext(model, train_df)\n",
        "y_test_pred = predict_fasttext(model, test_df)\n",
        "\n",
        "# Calculate macro F1 score\n",
        "train_f1 = f1_score(train_df['label'], y_train_pred, average='macro')\n",
        "test_f1 = f1_score(test_df['label'], y_test_pred, average='macro')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Train Macro F1 Score: {train_f1:.4f}\")\n",
        "print(f\"Test Macro F1 Score: {test_f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-class Classification"
      ],
      "metadata": {
        "id": "qiIg8ZY8qJlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fasttext\n",
        "import pandas as pd\n",
        "import fasttext\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load datasets\n",
        "multi_class_data = pd.read_csv(\"fake_news_classification_mal_train.csv\")\n",
        "multi_class_data[\"Label\"] = multi_class_data[\"Label\"].apply(lambda x: x.strip())\n",
        "class_names = sorted(list(multi_class_data[\"Label\"].unique()))\n",
        "train_df, valid_df = train_test_split(multi_class_data, test_size=0.3, random_state=42)\n",
        "\n",
        "test_df = pd.read_csv(\"fake_test_multiclass_labeled.csv\")\n",
        "test_df[\"Label\"] = test_df[\"Label\"].apply(lambda x: x.strip())\n",
        "\n",
        "\n",
        "train_df.dropna(subset=[\"News\", \"Label\"], inplace=True)\n",
        "test_df.dropna(subset=[\"News\", \"Label\"], inplace=True)\n",
        "train_df[\"Label\"] = train_df[\"Label\"].apply(lambda x: \"_\".join(x.strip().split(\" \")))\n",
        "test_df[\"Label\"] = test_df[\"Label\"].apply(lambda x: \"_\".join(x.strip().split(\" \")))\n",
        "\n",
        "train_df[\"News\"] = train_df[\"News\"].str.replace(\"\\n\", \" \")\n",
        "test_df[\"News\"] = test_df[\"News\"].str.replace(\"\\n\", \" \")\n",
        "# Prepare the data (fastText expects labels to start with '__label__' prefix)\n",
        "def preprocess_for_fasttext(df, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        for _, row in df.iterrows():\n",
        "            # fastText expects the label to be in the form '__label__<label>'\n",
        "            f.write(f\"__label__{row['Label']} {row['News']}\\n\")\n",
        "\n",
        "# Preprocess and save data in fastText's format\n",
        "preprocess_for_fasttext(train_df, 'train.ft')\n",
        "preprocess_for_fasttext(test_df, 'test.ft')\n",
        "\n",
        "# Train a fastText classifier\n",
        "model = fasttext.train_supervised(input='train.ft', epoch=10, lr=0.1, neg=5, loss='hs')\n",
        "                                  # epoch=10,          # Reduce number of epochs to prevent overfitting\n",
        "                                  # lr=0.05,           # Lower learning rate for more gradual learning\n",
        "                                  # dim=50,            # Reduce dimension of word vectors (default is 100)\n",
        "                                  # wordNgrams=1,      # Reduce the size of word n-grams (use 1 for unigrams)\n",
        "                                  # neg=5,             # Use negative sampling to improve generalization\n",
        "                                  # loss='hs',         # Use hierarchical softmax (faster and often better for smaller datasets)\n",
        "                                  # thread=4)          # Use multiple threads for faster training\n",
        "\n",
        "\n",
        "print(train_df.head())\n",
        "print(test_df.head())\n",
        "# Make predictions on train and test data\n",
        "def predict_fasttext(model, df):\n",
        "    predictions = []\n",
        "    for _, row in df.iterrows():\n",
        "        # Predict the label for the text using the trained model\n",
        "        # print(\"\\n\"+row['News'])\n",
        "        labels, _ = model.predict(row['News'].strip())  # fastText outputs tuple (labels, probabilities)\n",
        "        predictions.append(labels[0].replace('__label__', ''))  # Get the first label and remove the prefix\n",
        "    return predictions\n",
        "\n",
        "y_train_pred = predict_fasttext(model, train_df)\n",
        "y_test_pred = predict_fasttext(model, test_df)\n",
        "\n",
        "# Calculate macro F1 score\n",
        "train_f1 = f1_score(train_df['Label'], y_train_pred, average='macro')\n",
        "test_f1 = f1_score(test_df['Label'], y_test_pred, average='macro')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Train Macro F1 Score: {train_f1:.4f}\")\n",
        "print(f\"Test Macro F1 Score: {test_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "jWNqETrRxf2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af87317-152b-4f57-f18a-7eb7412185cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "                    ID                                               News  \\\n",
            "1565  FAKE_MAL_TR_1566       മഞ്ഞ് ഉരുകുന്നില്ല, കറുത്തിരുണ്ടു പൊള്ളുന്നു   \n",
            "277   FAKE_MAL_TR_0278  ചാർമാഡി ഘട്ടിൽ ജൂലൈ 25 ന് നടന്ന വെള്ളപൊക്കത്തി...   \n",
            "1754  FAKE_MAL_TR_1755  കാശ്മീരിലെ മച്ചില്‍ എന്‍കൗണ്ടറില്‍ അവസാനം മോദി...   \n",
            "358   FAKE_MAL_TR_0359  കർണാടക പോളിംഗ് സ്‌റ്റേഷനിലെ കള്ളവോട്ട് ദൃശ്യങ്...   \n",
            "1053  FAKE_MAL_TR_1054  സ്വപ്ന സുരേഷിനെ പിടികൂടിയത് ബാംഗ്ലൂരിൽ പിണറായി...   \n",
            "\n",
            "             Label  \n",
            "1565         FALSE  \n",
            "277          FALSE  \n",
            "1754  MOSTLY_FALSE  \n",
            "358   MOSTLY_FALSE  \n",
            "1053         FALSE  \n",
            "               S.no                                               News  Label\n",
            "0  FAKE_MAL_TE_0001  കേരളത്തില്‍ പുരുഷന്മാര്‍ക്ക് രണ്ട് ഭാര്യമാര്‍ ...  FALSE\n",
            "1  FAKE_MAL_TE_0002  പാർട്ടിയുടെ കൊടിക്ക് മഹത്വം ഉണ്ടെന്നും സംരംഭങ്...  FALSE\n",
            "2  FAKE_MAL_TE_0003  നവകേരള സദസ്സ്: കാട്ടാക്കട ക്രിസ്ത്യൻ കോളേജ് കവ...  FALSE\n",
            "3  FAKE_MAL_TE_0004  ശബരിമലയില്‍ അയ്യപ്പ ഭക്തന്‍റെ തല പോലീസ് അടിച്ച...  FALSE\n",
            "4  FAKE_MAL_TE_0005  ബൈക്കുകള്‍ സ്വന്തം ജില്ലയില്‍ മാത്രം ഉപയോഗിക്ക...  FALSE\n",
            "Train Macro F1 Score: 0.2090\n",
            "Test Macro F1 Score: 0.1667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('lr', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "model.fit(train_df['News'], train_df['Label'])\n",
        "y_train_pred = model.predict(train_df['News'])\n",
        "y_test_pred = model.predict(test_df['News'])\n",
        "\n",
        "train_f1 = f1_score(train_df['Label'], y_train_pred, average='macro')\n",
        "test_f1 = f1_score(test_df['Label'], y_test_pred, average='macro')\n",
        "print(train_f1)\n",
        "print(test_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVauXoNzPqm3",
        "outputId": "844f03ec-92f1-4f46-e162-f8a6b998f959"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2973595097488549\n",
            "0.202854912456786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gBm6ViPYP7u9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}