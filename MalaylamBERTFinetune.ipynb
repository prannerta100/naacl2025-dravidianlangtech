{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f915aa2-07b8-44ee-899e-751f35a2e393",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f860d-17ee-4a7c-a006-a977f18509df",
   "metadata": {},
   "source": [
    "| Experiment | Date | Details | Macro F1 | Comments |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| MalayalamBERT finetune | 2024-23-12 | just finetuned for 2 class classification | .8196 |  |\n",
    "| GPT4o and slightly better prompt | 2025-01-02 | wrote a prompt and gave 100 random training examples as context | .7823 |  |\n",
    "\n",
    "\n",
    "\n",
    "<!-- | GPT4o mini prompt | 2025-01-02 | wrote a prompt and gave 100 random training examples as context | .6848 |  |\n",
    "| GPT4o and slightly better prompt | 2025-01-02 | wrote a prompt and gave 100 random training examples as context | .7448 |  | -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e30dbfe-ca33-4ab1-a595-c911cf0c0c97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Malayalam BERT finetune (run this section until the end to generate the submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b973bc-75a4-47d2-adbb-afd9a28bc04a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/malayalam-bert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_353/239469473.py:60: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 02:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Original</th>\n",
       "      <th>Recall Original</th>\n",
       "      <th>F1 Original</th>\n",
       "      <th>Precision Fake</th>\n",
       "      <th>Recall Fake</th>\n",
       "      <th>F1 Fake</th>\n",
       "      <th>Macro Avg F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690118</td>\n",
       "      <td>0.498160</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.009780</td>\n",
       "      <td>0.019185</td>\n",
       "      <td>0.498141</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.662819</td>\n",
       "      <td>0.341002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.688300</td>\n",
       "      <td>0.666589</td>\n",
       "      <td>0.741104</td>\n",
       "      <td>0.740291</td>\n",
       "      <td>0.745721</td>\n",
       "      <td>0.742996</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.736453</td>\n",
       "      <td>0.739184</td>\n",
       "      <td>0.741090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.688300</td>\n",
       "      <td>0.622977</td>\n",
       "      <td>0.777914</td>\n",
       "      <td>0.770142</td>\n",
       "      <td>0.794621</td>\n",
       "      <td>0.782190</td>\n",
       "      <td>0.786260</td>\n",
       "      <td>0.761084</td>\n",
       "      <td>0.773467</td>\n",
       "      <td>0.777828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.637800</td>\n",
       "      <td>0.593057</td>\n",
       "      <td>0.802454</td>\n",
       "      <td>0.778027</td>\n",
       "      <td>0.848411</td>\n",
       "      <td>0.811696</td>\n",
       "      <td>0.831978</td>\n",
       "      <td>0.756158</td>\n",
       "      <td>0.792258</td>\n",
       "      <td>0.801977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.637800</td>\n",
       "      <td>0.585669</td>\n",
       "      <td>0.802454</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>0.885086</td>\n",
       "      <td>0.818079</td>\n",
       "      <td>0.861357</td>\n",
       "      <td>0.719212</td>\n",
       "      <td>0.783893</td>\n",
       "      <td>0.800986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load the pretrained Malayalam BERT model and tokenizer\n",
    "model_name = \"l3cube-pune/malayalam-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv(\"Fake_train.csv\")\n",
    "valid_data = pd.read_csv(\"Fake_dev.csv\")\n",
    "\n",
    "# Preprocess datasets: Tokenize text and encode labels\n",
    "def preprocess(data):\n",
    "    tokenized = tokenizer(list(data[\"text\"]), truncation=True, padding=\"max_length\", max_length=512)\n",
    "    tokenized[\"label\"] = data[\"label\"].map({\"original\": 0, \"Fake\": 1}).values\n",
    "    return tokenized\n",
    "\n",
    "train_dataset = Dataset.from_dict(preprocess(train_data))\n",
    "valid_dataset = Dataset.from_dict(preprocess(valid_data))\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    # load_best_model_at_end=True,\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"macro_avg_f1\"\n",
    "\n",
    ")\n",
    "\n",
    "# Define metrics for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    report = classification_report(labels, preds, target_names=[\"original\", \"Fake\"], output_dict=True)\n",
    "    return {\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"precision_original\": report[\"original\"][\"precision\"],\n",
    "        \"recall_original\": report[\"original\"][\"recall\"],\n",
    "        \"f1_original\": report[\"original\"][\"f1-score\"],\n",
    "        \"precision_Fake\": report[\"Fake\"][\"precision\"],\n",
    "        \"recall_Fake\": report[\"Fake\"][\"recall\"],\n",
    "        \"f1_Fake\": report[\"Fake\"][\"f1-score\"],\n",
    "        \"macro_avg_f1\": 0.5 * (report[\"Fake\"][\"f1-score\"] + report[\"original\"][\"f1-score\"])\n",
    "    }\n",
    "\n",
    "# Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on the train and validation datasets\n",
    "train_results = trainer.evaluate(train_dataset)\n",
    "valid_results = trainer.evaluate(valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08181317-cdaf-4019-9432-e98051a396ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"fake_test_binary_with_labels.csv\") #pd.read_csv(\"Fake_train.csv\") #\n",
    "# test_data[\"label\"] = [\"Fake\"] * 510 + [\"original\"] * 509\n",
    "test_dataset = Dataset.from_dict(preprocess(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "243f7335-37a0-43a5-b1b2-4c525010866f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = np.argmax(trainer.predict(test_dataset).predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e7ded42-ef93-4e38-a823-10f75e543325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7709    0.8809    0.8222       512\n",
      "           1     0.8594    0.7357    0.7928       507\n",
      "\n",
      "    accuracy                         0.8086      1019\n",
      "   macro avg     0.8152    0.8083    0.8075      1019\n",
      "weighted avg     0.8150    0.8086    0.8076      1019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred=test_preds, y_true=1 * (test_data[\"label\"] == \"Fake\"), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7836830f-4428-40a6-bb8f-b4758d619f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [\"original\", \"Fake\"]\n",
    "test_data[\"prediction\"] = [labels[int(x)] for x in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f8841f6-da25-4b83-8a82-69ffba2db0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data.drop(columns=[\"label\"]).to_csv(\"lowes_task1_run.tsv\",sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0575a-3706-4c52-9949-5ef6ad9ae78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the custom Trainer\n",
    "# trainer = CustomTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=valid_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff01e3a4-3751-4b1c-917f-40320cfacc93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fake news (multiple classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c3560-a703-4365-a705-430b98af152e",
   "metadata": {},
   "source": [
    "| Experiment | Date | Details | Macro F1 | Comments |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| MalayalamBERT finetune | 2024-23-12 | just finetuned for multi-class classification | .2153 |  |\n",
    "|  +focal loss raised to 0.1 weights and | |  | .2153 |  |\n",
    "|  GPT 4o | |  | .2156 |  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3313e6-fd03-4d99-9877-1093e7f16daf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Malayalam BERT finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ebc8a9-d058-49b1-8322-b293926c01a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/malayalam-bert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_3482605/96946939.py:60: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Macro Avg F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.387423</td>\n",
       "      <td>0.031564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.386181</td>\n",
       "      <td>0.163474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.385138</td>\n",
       "      <td>0.165552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.384433</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.384158</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load datasets\n",
    "multi_class_data = pd.read_csv(\"fake_news_classification_mal_train.csv\")\n",
    "multi_class_data[\"Label\"] = multi_class_data[\"Label\"].apply(lambda x: x.strip())\n",
    "class_names = sorted(list(multi_class_data[\"Label\"].unique()))\n",
    "train_data, valid_data = train_test_split(multi_class_data, test_size=0.3, random_state=42)\n",
    "\n",
    "test_data = pd.read_csv(\"fake_test_multiclass_labeled.csv\")\n",
    "test_data[\"Label\"] = test_data[\"Label\"].apply(lambda x: x.strip())\n",
    "valid_data = test_data\n",
    "\n",
    "# Load the pretrained Malayalam BERT model and tokenizer\n",
    "model_name = \"l3cube-pune/malayalam-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(class_names))\n",
    "\n",
    "# Preprocess datasets: Tokenize text and encode labels\n",
    "def preprocess(data):\n",
    "    tokenized = tokenizer(list(data[\"News\"]), truncation=True, padding=\"max_length\", max_length=256)\n",
    "    tokenized[\"label\"] = data[\"Label\"].map({class_name: i for i, class_name in enumerate(class_names)}).values\n",
    "    return tokenized\n",
    "\n",
    "train_dataset = Dataset.from_dict(preprocess(train_data))\n",
    "valid_dataset = Dataset.from_dict(preprocess(valid_data))\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    # load_best_model_at_end=True,\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"macro_avg_f1\"\n",
    "\n",
    ")\n",
    "\n",
    "# Define metrics for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    report = classification_report(labels, preds, target_names=class_names, output_dict=True)\n",
    "    return {\n",
    "        \"macro_avg_f1\":np.mean([report[class_name][\"f1-score\"] for class_name in class_names])\n",
    "    }\n",
    "\n",
    "# Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on the train and validation datasets\n",
    "train_results = trainer.evaluate(train_dataset)\n",
    "valid_results = trainer.evaluate(valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e4cef9-75d3-4315-9577-44d44494704c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3812459707260132,\n",
       " 'eval_macro_avg_f1': 0.2089715536105033,\n",
       " 'eval_runtime': 6.8906,\n",
       " 'eval_samples_per_second': 193.018,\n",
       " 'eval_steps_per_second': 0.871,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7d9ce7-e546-4e19-a802-51916e58bdfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3841580152511597,\n",
       " 'eval_macro_avg_f1': 0.16666666666666666,\n",
       " 'eval_runtime': 1.094,\n",
       " 'eval_samples_per_second': 182.818,\n",
       " 'eval_steps_per_second': 0.914,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa4ebc-d27c-4acd-9081-fbe7a5534006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b99d316-8ffd-4709-b606-e5c92deef561",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Finetune with synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657fd984-bc21-4f88-83b7-209e02eee6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load datasets\n",
    "multi_class_data = pd.concat([\n",
    "    pd.read_csv(\"fake_news_classification_mal_train.csv\"), \n",
    "    pd.read_csv(\"fake_news_classification_mal_train_synthetic_data.csv\")\n",
    "], axis=0)\n",
    "multi_class_data.drop_duplicates(subset=[\"News\"], inplace=True)\n",
    "multi_class_data[\"Label\"] = multi_class_data[\"Label\"].apply(lambda x: x.strip())\n",
    "class_names = sorted(list(multi_class_data[\"Label\"].unique()))\n",
    "train_data, valid_data = train_test_split(multi_class_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Load the pretrained Malayalam BERT model and tokenizer\n",
    "model_name = \"l3cube-pune/malayalam-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(class_names))\n",
    "\n",
    "# Preprocess datasets: Tokenize text and encode labels\n",
    "def preprocess(data):\n",
    "    tokenized = tokenizer(list(data[\"News\"]), truncation=True, padding=\"max_length\", max_length=256)\n",
    "    tokenized[\"label\"] = data[\"Label\"].map({class_name: i for i, class_name in enumerate(class_names)}).values\n",
    "    return tokenized\n",
    "\n",
    "train_dataset = Dataset.from_dict(preprocess(train_data))\n",
    "valid_dataset = Dataset.from_dict(preprocess(valid_data))\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    # load_best_model_at_end=True,\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"macro_avg_f1\"\n",
    "\n",
    ")\n",
    "pred_names = []\n",
    "# Define metrics for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    pred_names = [class_names[i] for i in preds]\n",
    "    report = classification_report(labels, preds, target_names=class_names, output_dict=True)\n",
    "    return {\n",
    "        \"macro_avg_f1\":np.mean([report[class_name][\"f1-score\"] for class_name in class_names])\n",
    "    }\n",
    "\n",
    "# Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on the train and validation datasets\n",
    "train_results = trainer.evaluate(train_dataset)\n",
    "valid_results = trainer.evaluate(valid_dataset)\n",
    "valid_data[\"pred\"] = pred_names\n",
    "valid_data.to_csv(\"./validation_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b731248a-5f0b-44e7-9392-7a4202ec9cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3792507648468018,\n",
       " 'eval_macro_avg_f1': 0.18357487922705315,\n",
       " 'eval_runtime': 3.5984,\n",
       " 'eval_samples_per_second': 218.428,\n",
       " 'eval_steps_per_second': 1.112,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "974ff3a7-1aae-40e3-80ed-e756d8390756",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2372, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_class_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae34e75-1dc6-4fad-a59a-b44f43028d16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Malayalam BERT finetune with focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f546a32f-cbe3-47cd-8f3e-a2c2b9270b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/malayalam-bert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_305688/1723291829.py:96: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Macro Avg F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.711576</td>\n",
       "      <td>0.189386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.710390</td>\n",
       "      <td>0.215285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.709303</td>\n",
       "      <td>0.215285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.708577</td>\n",
       "      <td>0.215285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.708304</td>\n",
       "      <td>0.215285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Load datasets\n",
    "multi_class_data = pd.read_csv(\"fake_news_classification_mal_train.csv\")\n",
    "multi_class_data[\"Label\"] = multi_class_data[\"Label\"].apply(lambda x: x.strip())\n",
    "class_names = sorted(list(multi_class_data[\"Label\"].unique()))\n",
    "train_data, valid_data = train_test_split(multi_class_data, test_size=0.3, random_state=42)\n",
    "class_weights = [1 / (train_data[\"Label\"].value_counts()[class_name]) ** 0.1 for class_name in class_names]\n",
    "\n",
    "# Load the pretrained Malayalam BERT model and tokenizer\n",
    "model_name = \"l3cube-pune/malayalam-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(class_names))\n",
    "\n",
    "# Preprocess datasets: Tokenize text and encode labels\n",
    "def preprocess(data):\n",
    "    tokenized = tokenizer(list(data[\"News\"]), truncation=True, padding=\"max_length\", max_length=256)\n",
    "    tokenized[\"label\"] = data[\"Label\"].map({class_name: i for i, class_name in enumerate(class_names)}).values\n",
    "    return tokenized\n",
    "\n",
    "train_dataset = Dataset.from_dict(preprocess(train_data))\n",
    "valid_dataset = Dataset.from_dict(preprocess(valid_data))\n",
    "\n",
    "# Focal Loss Implementation\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # Can be used to give weights to classes\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = F.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=logits.size(-1)).float()\n",
    "        pt = (probs * targets_one_hot).sum(dim=-1)  # Probability of the true class\n",
    "        log_pt = torch.log(pt + 1e-12)  # Add small value to avoid log(0)\n",
    "        focal_loss = -(1 - pt) ** self.gamma * log_pt  # Apply the focal loss formula\n",
    "\n",
    "        # Apply class weights if provided\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha.gather(0, targets)\n",
    "            focal_loss = focal_loss * alpha_t\n",
    "\n",
    "        # Reduction\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# Define custom Trainer with Focal Loss\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        # print(f\"Unexpected kwargs: {kwargs}\")  # Log unexpected arguments\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fn = FocalLoss(gamma=0.1, alpha=torch.tensor(class_weights).to(\"cuda\"))  # Optionally adjust alpha\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"macro_avg_f1\"\n",
    ")\n",
    "\n",
    "# Define metrics for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    report = classification_report(labels, preds, target_names=class_names, output_dict=True)\n",
    "    return {\n",
    "        \"macro_avg_f1\": np.mean([report[class_name][\"f1-score\"] for class_name in class_names])\n",
    "    }\n",
    "\n",
    "# Use the custom Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on the train and validation datasets\n",
    "train_results = trainer.evaluate(train_dataset)\n",
    "valid_results = trainer.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bab55ff-d835-4195-b2ef-0273eed8bd9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  Fasttext model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1a9d8ee-75b6-456e-97d2-56b0e949a284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def csv_to_fasttext(input_df, output_txt, text_col=\"News\", label_col=\"Label\"):\n",
    "    with open(output_txt, 'w') as f:\n",
    "        for _, row in input_df.iterrows():\n",
    "            label = f\"__label__{row[label_col]}\"\n",
    "            text = row[text_col].replace(\"\\n\", \" \")  # Remove newline characters\n",
    "            f.write(f\"{label} {text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cbdc50b-6ab9-4813-b86a-43eb3dbdc751",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m validation_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m csv_to_fasttext(train_data, train_file)\n\u001b[0;32m----> 8\u001b[0m csv_to_fasttext(\u001b[43mvalidation_data\u001b[49m, validation_file)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train the FastText model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m fasttext\u001b[38;5;241m.\u001b[39mtrain_supervised(\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtrain_file,\n\u001b[1;32m     13\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,  \u001b[38;5;66;03m# Learning rate\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Loss function\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validation_data' is not defined"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "# Paths to dataset files\n",
    "train_file = \"train.txt\"\n",
    "validation_file = \"validation.txt\"\n",
    "\n",
    "csv_to_fasttext(train_data, train_file)\n",
    "csv_to_fasttext(validation_data, validation_file)\n",
    "\n",
    "# Train the FastText model\n",
    "model = fasttext.train_supervised(\n",
    "    input=train_file,\n",
    "    lr=1.0,  # Learning rate\n",
    "    epoch=25,  # Number of epochs\n",
    "    wordNgrams=2,  # Use word n-grams\n",
    "    verbose=2,  # Verbosity level\n",
    "    loss=\"softmax\"  # Loss function\n",
    ")\n",
    "\n",
    "# Evaluate on the validation set\n",
    "validation_result = model.test(validation_file)\n",
    "print(\"\\nValidation Results:\")\n",
    "print(f\"Precision: {validation_result.precision:.4f}\")\n",
    "print(f\"Recall: {validation_result.recall:.4f}\")\n",
    "print(f\"Number of samples: {validation_result.nexamples}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_result = model.test(test_file)\n",
    "print(\"\\nTest Results:\")\n",
    "print(f\"Precision: {test_result.precision:.4f}\")\n",
    "print(f\"Recall: {test_result.recall:.4f}\")\n",
    "print(f\"Number of samples: {test_result.nexamples}\")\n",
    "\n",
    "# Save the model\n",
    "model.save_model(\"fasttext_model.bin\")\n",
    "\n",
    "# Example of predicting labels for new texts\n",
    "texts = [\"This is an example text.\", \"Another example sentence.\"]\n",
    "predictions = [model.predict(text) for text in texts]\n",
    "for text, prediction in zip(texts, predictions):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Prediction: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "233058e3-e28b-4877-86f2-d6bec06c24ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/pandas/compat/_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfake_news_classification_mal_test.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m~/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/pandas/io/excel/_base.py:1567\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[0;32m-> 1567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py:552\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    539\u001b[0m     engine_kwargs: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    540\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    541\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;124;03m        Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    554\u001b[0m         filepath_or_buffer,\n\u001b[1;32m    555\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    556\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[1;32m    557\u001b[0m     )\n",
      "File \u001b[0;32m~/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/pandas/compat/_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "pd.read_excel(\"fake_news_classification_mal_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535285e0-287e-4538-9e76-a9f6e60c3113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe7c5c-ff07-44f9-92ed-c2f88da68550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00d5ede2-4e6d-41d0-850e-877136dd37f1",
   "metadata": {},
   "source": [
    "## Paper Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce60bd0-e7b3-460d-acc4-0bf1b419d2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"Fake_train.csv\")\n",
    "valid_data = pd.read_csv(\"Fake_dev.csv\")\n",
    "test_data = pd.read_csv(\"fake_test_binary_with_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f9ff04d-a88d-4987-a4df-b9b0d225003b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " original    1658\n",
       " Fake        1599\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " original    409\n",
       " Fake        406\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " original    512\n",
       " Fake        507\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"label\"].value_counts(), valid_data[\"label\"].value_counts(), test_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483ec654-180f-4395-b0b9-80d9e2008660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Macro F1 Score: 0.9278\n",
      "Test Macro F1 Score: 0.7690\n"
     ]
    }
   ],
   "source": [
    "# Simple tfidf + lr\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv('Fake_train.csv')\n",
    "test_df = pd.read_csv('fake_test_binary_with_labels.csv')\n",
    "\n",
    "# Prepare the data\n",
    "X_train = train_df['text']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['text']\n",
    "y_test = test_df['label']\n",
    "\n",
    "# Optionally, split train set further to validate performance on a smaller train split\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the TF-IDF + Logistic Regression pipeline\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    LogisticRegression(max_iter=1000)  # Adjust max_iter if you run into convergence issues\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train and test data\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate using macro F1 score\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "print(f\"Train Macro F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Test Macro F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99116ff5-ba63-4668-be41-d92ca08da218",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  19466\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:   21976 lr:  0.000000 avg.loss:  0.242259 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to avoid copy while creating an array as requested.\nIf using `np.array(obj, copy=False)` replace it with `np.asarray(obj)` to allow a copy when needed (no behavior change in NumPy 1.x).\nFor more details, see https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(labels[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__label__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))  \u001b[38;5;66;03m# Get the first label and remove the prefix\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n\u001b[0;32m---> 32\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_fasttext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m predict_fasttext(model, test_df)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Calculate macro F1 score\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 28\u001b[0m, in \u001b[0;36mpredict_fasttext\u001b[0;34m(model, df)\u001b[0m\n\u001b[1;32m     25\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Predict the label for the text using the trained model\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     labels, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# fastText outputs tuple (labels, probabilities)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(labels[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__label__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))  \u001b[38;5;66;03m# Get the first label and remove the prefix\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/fasttext/FastText.py:239\u001b[0m, in \u001b[0;36m_FastText.predict\u001b[0;34m(self, text, k, threshold, on_unicode_error)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     probs, labels \u001b[38;5;241m=\u001b[39m ([], ())\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to avoid copy while creating an array as requested.\nIf using `np.array(obj, copy=False)` replace it with `np.asarray(obj)` to allow a copy when needed (no behavior change in NumPy 1.x).\nFor more details, see https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('Fake_train.csv')\n",
    "test_df = pd.read_csv('fake_test_binary_with_labels.csv')\n",
    "\n",
    "# Prepare the data (fastText expects labels to start with '__label__' prefix)\n",
    "def preprocess_for_fasttext(df, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            # fastText expects the label to be in the form '__label__<label>'\n",
    "            f.write(f\"__label__{row['label']} {row['text']}\\n\")\n",
    "\n",
    "# Preprocess and save data in fastText's format\n",
    "preprocess_for_fasttext(train_df, 'train.ft')\n",
    "preprocess_for_fasttext(test_df, 'test.ft')\n",
    "\n",
    "# Train a fastText classifier\n",
    "model = fasttext.train_supervised(input='train.ft', epoch=25, lr=0.1, wordNgrams=2)\n",
    "\n",
    "# Make predictions on train and test data\n",
    "def predict_fasttext(model, df):\n",
    "    predictions = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Predict the label for the text using the trained model\n",
    "        labels, _ = model.predict(row['text'])  # fastText outputs tuple (labels, probabilities)\n",
    "        predictions.append(labels[0].replace('__label__', ''))  # Get the first label and remove the prefix\n",
    "    return predictions\n",
    "\n",
    "y_train_pred = predict_fasttext(model, train_df)\n",
    "y_test_pred = predict_fasttext(model, test_df)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "train_f1 = f1_score(train_df['label'], y_train_pred, average='macro')\n",
    "test_f1 = f1_score(test_df['label'], y_test_pred, average='macro')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Train Macro F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Test Macro F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a6f2735-a67e-4c25-aa6e-9d9fd869fe91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "FALSE           1220\n",
       "MOSTLY FALSE     295\n",
       "FALSE            166\n",
       "HALF TRUE        162\n",
       "PARTLY FALSE      57\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"fake_news_classification_mal_train.csv\")[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ef57411-871f-4962-aaec-9693a8e4d7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "FALSE           100\n",
       "MOSTLY FALSE     56\n",
       "HALF TRUE        37\n",
       "PARTLY FALSE      7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"fake_test_multiclass_labeled.csv\")[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe43de6-dc1e-4266-aed8-12c03d49a91b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st-fake-news-kernel",
   "language": "python",
   "name": "st-fake-news-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
