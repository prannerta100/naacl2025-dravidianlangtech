{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2790"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "AWM = pd.read_csv('/Users/5036365/Documents/Dravidian Lang Tech Data/Abusive Towards Women/AWT_train.csv')\n",
    "len(AWM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AWM_val = pd.read_csv('/Users/5036365/Documents/Dravidian Lang Tech Data/Abusive Towards Women/AWT_dev.csv')\n",
    "len(AWM_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "label = []\n",
    "for i in range(0,len(AWM)):\n",
    "    if AWM['Class'][i] =='Abusive':\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "AWM['label']=np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_val = []\n",
    "for i in range(0,len(AWM_val)):\n",
    "    if AWM_val['Class'][i] =='Abusive':\n",
    "        label_val.append(1)\n",
    "    else:\n",
    "        label_val.append(0)\n",
    "AWM_val['label']=np.array(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(AWM_val['Text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/5036365/Documents/text-recommendation/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    " \n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments, TrainerCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Split the data into train and test sets\n",
    "#train_texts, test_texts, train_labels, test_labels = train_test_split(AWM['Text'], AWM['label'], test_size=0.2)\n",
    " \n",
    "\n",
    "train_texts, train_labels,test_texts, test_labels = AWM['Text'], AWM['label'],AWM_val['Text'], AWM_val['label']\n",
    "# Load tokenizer\n",
    "model_name = \"xlm-roberta-base\" #distlbert-uncased\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    " \n",
    "# Tokenize dataset\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples.to_list(), truncation=True, padding=\"max_length\", max_length=128)\n",
    " \n",
    "train_encodings = preprocess_function(train_texts)\n",
    "test_encodings = preprocess_function(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Hugging Face Dataset format, and include 'labels' in the Dataset\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask'],\n",
    "    'labels': train_labels  # Ensure labels are included\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'input_ids': test_encodings['input_ids'],\n",
    "    'attention_mask': test_encodings['attention_mask'],\n",
    "    'labels': test_labels  # Ensure labels are included\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    " \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4319cb70511b4cf48c2c39204f68d7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7014, 'grad_norm': 2.3903329372406006, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.04}\n",
      "{'loss': 0.6957, 'grad_norm': 2.638183116912842, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.07}\n",
      "{'loss': 0.6896, 'grad_norm': 3.6798179149627686, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.11}\n",
      "{'loss': 0.7053, 'grad_norm': 2.88969087600708, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.14}\n",
      "{'loss': 0.703, 'grad_norm': 1.2983325719833374, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.18}\n",
      "{'loss': 0.6876, 'grad_norm': 1.1121445894241333, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.22}\n",
      "{'loss': 0.6892, 'grad_norm': 2.459695339202881, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.25}\n",
      "{'loss': 0.6924, 'grad_norm': 1.7212798595428467, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.29}\n",
      "{'loss': 0.6905, 'grad_norm': 2.4521374702453613, 'learning_rate': 9.000000000000001e-07, 'epoch': 0.32}\n",
      "{'loss': 0.6907, 'grad_norm': 1.3130757808685303, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.36}\n",
      "{'loss': 0.6935, 'grad_norm': 2.1488187313079834, 'learning_rate': 1.1e-06, 'epoch': 0.39}\n",
      "{'loss': 0.6875, 'grad_norm': 2.2745754718780518, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.43}\n",
      "{'loss': 0.6943, 'grad_norm': 6.772027015686035, 'learning_rate': 1.3e-06, 'epoch': 0.47}\n",
      "{'loss': 0.6885, 'grad_norm': 1.8722587823867798, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.5}\n",
      "{'loss': 0.6913, 'grad_norm': 3.3483126163482666, 'learning_rate': 1.5e-06, 'epoch': 0.54}\n",
      "{'loss': 0.6941, 'grad_norm': 5.0797505378723145, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.57}\n",
      "{'loss': 0.7069, 'grad_norm': 2.3527626991271973, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.61}\n",
      "{'loss': 0.6839, 'grad_norm': 2.309709072113037, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.65}\n",
      "{'loss': 0.6933, 'grad_norm': 3.3258113861083984, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.68}\n",
      "{'loss': 0.7024, 'grad_norm': 4.739363670349121, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.72}\n",
      "{'loss': 0.7017, 'grad_norm': 2.9956681728363037, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.75}\n",
      "{'loss': 0.6852, 'grad_norm': 1.9020164012908936, 'learning_rate': 2.2e-06, 'epoch': 0.79}\n",
      "{'loss': 0.6876, 'grad_norm': 4.796145915985107, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.82}\n",
      "{'loss': 0.6914, 'grad_norm': 1.1441503763198853, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.86}\n",
      "{'loss': 0.6962, 'grad_norm': 2.0357112884521484, 'learning_rate': 2.5e-06, 'epoch': 0.9}\n",
      "{'loss': 0.6882, 'grad_norm': 4.13230562210083, 'learning_rate': 2.6e-06, 'epoch': 0.93}\n",
      "{'loss': 0.6921, 'grad_norm': 3.1364545822143555, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68aba146c0204448ab9993fc96a03c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6909783482551575, 'eval_accuracy': 0.507168458781362, 'eval_macro_f1': 0.3428912783751494, 'eval_weighted_f1': 0.34524650676806995, 'eval_runtime': 5.2817, 'eval_samples_per_second': 105.647, 'eval_steps_per_second': 13.253, 'epoch': 1.0}\n",
      "{'loss': 0.7003, 'grad_norm': 3.077040672302246, 'learning_rate': 2.8000000000000003e-06, 'epoch': 1.0}\n",
      "{'loss': 0.692, 'grad_norm': 2.6414124965667725, 'learning_rate': 2.9e-06, 'epoch': 1.04}\n",
      "{'loss': 0.7012, 'grad_norm': 5.285091876983643, 'learning_rate': 3e-06, 'epoch': 1.08}\n",
      "{'loss': 0.6842, 'grad_norm': 1.8843662738800049, 'learning_rate': 3.1000000000000004e-06, 'epoch': 1.11}\n",
      "{'loss': 0.6812, 'grad_norm': 7.641088962554932, 'learning_rate': 3.2000000000000003e-06, 'epoch': 1.15}\n",
      "{'loss': 0.6792, 'grad_norm': 3.2397119998931885, 'learning_rate': 3.3000000000000006e-06, 'epoch': 1.18}\n",
      "{'loss': 0.7072, 'grad_norm': 5.7334208488464355, 'learning_rate': 3.4000000000000005e-06, 'epoch': 1.22}\n",
      "{'loss': 0.6731, 'grad_norm': 8.81008243560791, 'learning_rate': 3.5e-06, 'epoch': 1.25}\n",
      "{'loss': 0.6406, 'grad_norm': 15.781182289123535, 'learning_rate': 3.6000000000000003e-06, 'epoch': 1.29}\n",
      "{'loss': 0.6595, 'grad_norm': 7.4423828125, 'learning_rate': 3.7e-06, 'epoch': 1.33}\n",
      "{'loss': 0.673, 'grad_norm': 8.248177528381348, 'learning_rate': 3.8000000000000005e-06, 'epoch': 1.36}\n",
      "{'loss': 0.6918, 'grad_norm': 8.446897506713867, 'learning_rate': 3.900000000000001e-06, 'epoch': 1.4}\n",
      "{'loss': 0.632, 'grad_norm': 8.865211486816406, 'learning_rate': 4.000000000000001e-06, 'epoch': 1.43}\n",
      "{'loss': 0.6033, 'grad_norm': 10.913430213928223, 'learning_rate': 4.1e-06, 'epoch': 1.47}\n",
      "{'loss': 0.6729, 'grad_norm': 7.831572532653809, 'learning_rate': 4.2000000000000004e-06, 'epoch': 1.51}\n",
      "{'loss': 0.6771, 'grad_norm': 19.55735969543457, 'learning_rate': 4.3e-06, 'epoch': 1.54}\n",
      "{'loss': 0.5727, 'grad_norm': 19.188949584960938, 'learning_rate': 4.4e-06, 'epoch': 1.58}\n",
      "{'loss': 0.5825, 'grad_norm': 12.072381973266602, 'learning_rate': 4.5e-06, 'epoch': 1.61}\n",
      "{'loss': 0.6497, 'grad_norm': 12.984907150268555, 'learning_rate': 4.600000000000001e-06, 'epoch': 1.65}\n",
      "{'loss': 0.6665, 'grad_norm': 21.147695541381836, 'learning_rate': 4.7e-06, 'epoch': 1.68}\n",
      "{'loss': 0.5765, 'grad_norm': 19.43037986755371, 'learning_rate': 4.800000000000001e-06, 'epoch': 1.72}\n",
      "{'loss': 0.5198, 'grad_norm': 26.918489456176758, 'learning_rate': 4.9000000000000005e-06, 'epoch': 1.76}\n",
      "{'loss': 0.5947, 'grad_norm': 15.395971298217773, 'learning_rate': 5e-06, 'epoch': 1.79}\n",
      "{'loss': 0.6415, 'grad_norm': 25.88051986694336, 'learning_rate': 4.944134078212291e-06, 'epoch': 1.83}\n",
      "{'loss': 0.6269, 'grad_norm': 23.640853881835938, 'learning_rate': 4.8882681564245816e-06, 'epoch': 1.86}\n",
      "{'loss': 0.6502, 'grad_norm': 17.694480895996094, 'learning_rate': 4.832402234636872e-06, 'epoch': 1.9}\n",
      "{'loss': 0.6433, 'grad_norm': 10.175230979919434, 'learning_rate': 4.776536312849163e-06, 'epoch': 1.94}\n",
      "{'loss': 0.6489, 'grad_norm': 26.37340545654297, 'learning_rate': 4.7206703910614525e-06, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a032d2d2ff704904a51d77985c45ce69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5921571850776672, 'eval_accuracy': 0.6971326164874552, 'eval_macro_f1': 0.6895867278921641, 'eval_weighted_f1': 0.6892397904854841, 'eval_runtime': 4.8429, 'eval_samples_per_second': 115.22, 'eval_steps_per_second': 14.454, 'epoch': 2.0}\n",
      "{'loss': 0.6015, 'grad_norm': 15.517420768737793, 'learning_rate': 4.664804469273743e-06, 'epoch': 2.01}\n",
      "{'loss': 0.5822, 'grad_norm': 22.91794204711914, 'learning_rate': 4.608938547486034e-06, 'epoch': 2.04}\n",
      "{'loss': 0.6645, 'grad_norm': 11.927367210388184, 'learning_rate': 4.553072625698324e-06, 'epoch': 2.08}\n",
      "{'loss': 0.5429, 'grad_norm': 18.64786720275879, 'learning_rate': 4.497206703910615e-06, 'epoch': 2.11}\n",
      "{'loss': 0.548, 'grad_norm': 31.189786911010742, 'learning_rate': 4.441340782122905e-06, 'epoch': 2.15}\n",
      "{'loss': 0.5408, 'grad_norm': 31.149423599243164, 'learning_rate': 4.385474860335196e-06, 'epoch': 2.19}\n",
      "{'loss': 0.581, 'grad_norm': 69.94064331054688, 'learning_rate': 4.3296089385474866e-06, 'epoch': 2.22}\n",
      "{'loss': 0.5738, 'grad_norm': 61.02717590332031, 'learning_rate': 4.273743016759777e-06, 'epoch': 2.26}\n",
      "{'loss': 0.571, 'grad_norm': 39.72026824951172, 'learning_rate': 4.217877094972068e-06, 'epoch': 2.29}\n",
      "{'loss': 0.5767, 'grad_norm': 19.350109100341797, 'learning_rate': 4.1620111731843575e-06, 'epoch': 2.33}\n",
      "{'loss': 0.5132, 'grad_norm': 22.98004913330078, 'learning_rate': 4.106145251396648e-06, 'epoch': 2.37}\n",
      "{'loss': 0.5344, 'grad_norm': 26.726442337036133, 'learning_rate': 4.050279329608939e-06, 'epoch': 2.4}\n",
      "{'loss': 0.6453, 'grad_norm': 13.342828750610352, 'learning_rate': 3.994413407821229e-06, 'epoch': 2.44}\n",
      "{'loss': 0.5931, 'grad_norm': 19.001575469970703, 'learning_rate': 3.93854748603352e-06, 'epoch': 2.47}\n",
      "{'loss': 0.4547, 'grad_norm': 12.813163757324219, 'learning_rate': 3.88268156424581e-06, 'epoch': 2.51}\n",
      "{'loss': 0.5745, 'grad_norm': 21.37640953063965, 'learning_rate': 3.826815642458101e-06, 'epoch': 2.54}\n",
      "{'loss': 0.7007, 'grad_norm': 28.49180030822754, 'learning_rate': 3.7709497206703915e-06, 'epoch': 2.58}\n",
      "{'loss': 0.5655, 'grad_norm': 19.26415252685547, 'learning_rate': 3.715083798882682e-06, 'epoch': 2.62}\n",
      "{'loss': 0.5678, 'grad_norm': 13.64140510559082, 'learning_rate': 3.6592178770949723e-06, 'epoch': 2.65}\n",
      "{'loss': 0.5321, 'grad_norm': 12.736516952514648, 'learning_rate': 3.603351955307263e-06, 'epoch': 2.69}\n",
      "{'loss': 0.5564, 'grad_norm': 14.972138404846191, 'learning_rate': 3.547486033519553e-06, 'epoch': 2.72}\n",
      "{'loss': 0.5315, 'grad_norm': 11.509037971496582, 'learning_rate': 3.4916201117318436e-06, 'epoch': 2.76}\n",
      "{'loss': 0.4801, 'grad_norm': 13.502803802490234, 'learning_rate': 3.435754189944134e-06, 'epoch': 2.8}\n",
      "{'loss': 0.5215, 'grad_norm': 12.74682331085205, 'learning_rate': 3.3798882681564248e-06, 'epoch': 2.83}\n",
      "{'loss': 0.5652, 'grad_norm': 7.564471244812012, 'learning_rate': 3.3240223463687154e-06, 'epoch': 2.87}\n",
      "{'loss': 0.4952, 'grad_norm': 11.962340354919434, 'learning_rate': 3.268156424581006e-06, 'epoch': 2.9}\n",
      "{'loss': 0.5096, 'grad_norm': 11.4348726272583, 'learning_rate': 3.2122905027932965e-06, 'epoch': 2.94}\n",
      "{'loss': 0.5495, 'grad_norm': 31.06681251525879, 'learning_rate': 3.1564245810055867e-06, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd9affc68dc4f72829845627a5d9f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6691585779190063, 'eval_accuracy': 0.6684587813620072, 'eval_macro_f1': 0.6581278667351096, 'eval_weighted_f1': 0.658553883833126, 'eval_runtime': 4.9075, 'eval_samples_per_second': 113.704, 'eval_steps_per_second': 14.264, 'epoch': 3.0}\n",
      "{'loss': 0.542, 'grad_norm': 18.41453742980957, 'learning_rate': 3.1005586592178773e-06, 'epoch': 3.01}\n",
      "{'loss': 0.5287, 'grad_norm': 4.783198356628418, 'learning_rate': 3.044692737430168e-06, 'epoch': 3.05}\n",
      "{'loss': 0.5751, 'grad_norm': 19.60125160217285, 'learning_rate': 2.9888268156424584e-06, 'epoch': 3.08}\n",
      "{'loss': 0.4973, 'grad_norm': 13.729207992553711, 'learning_rate': 2.9329608938547486e-06, 'epoch': 3.12}\n",
      "{'loss': 0.4631, 'grad_norm': 39.23911666870117, 'learning_rate': 2.877094972067039e-06, 'epoch': 3.15}\n",
      "{'loss': 0.4293, 'grad_norm': 17.194120407104492, 'learning_rate': 2.8212290502793298e-06, 'epoch': 3.19}\n",
      "{'loss': 0.5775, 'grad_norm': 27.676698684692383, 'learning_rate': 2.7653631284916204e-06, 'epoch': 3.23}\n",
      "{'loss': 0.4833, 'grad_norm': 27.039384841918945, 'learning_rate': 2.709497206703911e-06, 'epoch': 3.26}\n",
      "{'loss': 0.4532, 'grad_norm': 17.102672576904297, 'learning_rate': 2.6536312849162015e-06, 'epoch': 3.3}\n",
      "{'loss': 0.433, 'grad_norm': 46.07687759399414, 'learning_rate': 2.5977653631284917e-06, 'epoch': 3.33}\n",
      "{'loss': 0.5043, 'grad_norm': 22.395008087158203, 'learning_rate': 2.5418994413407823e-06, 'epoch': 3.37}\n",
      "{'loss': 0.5567, 'grad_norm': 11.219837188720703, 'learning_rate': 2.486033519553073e-06, 'epoch': 3.41}\n",
      "{'loss': 0.4842, 'grad_norm': 41.38856506347656, 'learning_rate': 2.4301675977653634e-06, 'epoch': 3.44}\n",
      "{'loss': 0.5116, 'grad_norm': 31.68389129638672, 'learning_rate': 2.374301675977654e-06, 'epoch': 3.48}\n",
      "{'loss': 0.404, 'grad_norm': 20.003896713256836, 'learning_rate': 2.318435754189944e-06, 'epoch': 3.51}\n",
      "{'loss': 0.515, 'grad_norm': 23.70376205444336, 'learning_rate': 2.2625698324022348e-06, 'epoch': 3.55}\n",
      "{'loss': 0.5419, 'grad_norm': 8.69550609588623, 'learning_rate': 2.2067039106145253e-06, 'epoch': 3.58}\n",
      "{'loss': 0.4532, 'grad_norm': 29.562091827392578, 'learning_rate': 2.150837988826816e-06, 'epoch': 3.62}\n",
      "{'loss': 0.4859, 'grad_norm': 23.975854873657227, 'learning_rate': 2.0949720670391065e-06, 'epoch': 3.66}\n",
      "{'loss': 0.4979, 'grad_norm': 32.5760612487793, 'learning_rate': 2.039106145251397e-06, 'epoch': 3.69}\n",
      "{'loss': 0.39, 'grad_norm': 55.23390579223633, 'learning_rate': 1.9832402234636873e-06, 'epoch': 3.73}\n",
      "{'loss': 0.4525, 'grad_norm': 21.872238159179688, 'learning_rate': 1.927374301675978e-06, 'epoch': 3.76}\n",
      "{'loss': 0.4422, 'grad_norm': 49.487579345703125, 'learning_rate': 1.8715083798882682e-06, 'epoch': 3.8}\n",
      "{'loss': 0.4782, 'grad_norm': 36.6365852355957, 'learning_rate': 1.8156424581005588e-06, 'epoch': 3.84}\n",
      "{'loss': 0.4855, 'grad_norm': 10.85700798034668, 'learning_rate': 1.7597765363128494e-06, 'epoch': 3.87}\n",
      "{'loss': 0.4638, 'grad_norm': 66.895751953125, 'learning_rate': 1.7039106145251397e-06, 'epoch': 3.91}\n",
      "{'loss': 0.5324, 'grad_norm': 11.303115844726562, 'learning_rate': 1.6480446927374303e-06, 'epoch': 3.94}\n",
      "{'loss': 0.5127, 'grad_norm': 66.77863311767578, 'learning_rate': 1.5921787709497207e-06, 'epoch': 3.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc844fbbec344e14b567d0a88fe01af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6389119625091553, 'eval_accuracy': 0.7114695340501792, 'eval_macro_f1': 0.7107924090974939, 'eval_weighted_f1': 0.7108927239052991, 'eval_runtime': 4.9184, 'eval_samples_per_second': 113.452, 'eval_steps_per_second': 14.232, 'epoch': 4.0}\n",
      "{'loss': 0.5484, 'grad_norm': 47.41437530517578, 'learning_rate': 1.5363128491620113e-06, 'epoch': 4.01}\n",
      "{'loss': 0.4893, 'grad_norm': 8.93497085571289, 'learning_rate': 1.4804469273743019e-06, 'epoch': 4.05}\n",
      "{'loss': 0.5275, 'grad_norm': 45.3161735534668, 'learning_rate': 1.4245810055865922e-06, 'epoch': 4.09}\n",
      "{'loss': 0.4761, 'grad_norm': 31.78418731689453, 'learning_rate': 1.3687150837988828e-06, 'epoch': 4.12}\n",
      "{'loss': 0.5174, 'grad_norm': 53.7054557800293, 'learning_rate': 1.3128491620111732e-06, 'epoch': 4.16}\n",
      "{'loss': 0.3359, 'grad_norm': 28.486665725708008, 'learning_rate': 1.2569832402234638e-06, 'epoch': 4.19}\n",
      "{'loss': 0.5365, 'grad_norm': 49.37507629394531, 'learning_rate': 1.2011173184357544e-06, 'epoch': 4.23}\n",
      "{'loss': 0.2885, 'grad_norm': 29.86622428894043, 'learning_rate': 1.1452513966480447e-06, 'epoch': 4.27}\n",
      "{'loss': 0.3565, 'grad_norm': 25.13849449157715, 'learning_rate': 1.0893854748603353e-06, 'epoch': 4.3}\n",
      "{'loss': 0.4878, 'grad_norm': 23.478857040405273, 'learning_rate': 1.033519553072626e-06, 'epoch': 4.34}\n",
      "{'loss': 0.4823, 'grad_norm': 32.05110549926758, 'learning_rate': 9.776536312849163e-07, 'epoch': 4.37}\n",
      "{'loss': 0.4183, 'grad_norm': 38.02832794189453, 'learning_rate': 9.217877094972068e-07, 'epoch': 4.41}\n",
      "{'loss': 0.5267, 'grad_norm': 4.639560222625732, 'learning_rate': 8.659217877094973e-07, 'epoch': 4.44}\n",
      "{'loss': 0.5569, 'grad_norm': 60.32899475097656, 'learning_rate': 8.100558659217877e-07, 'epoch': 4.48}\n",
      "{'loss': 0.4135, 'grad_norm': 15.430403709411621, 'learning_rate': 7.541899441340783e-07, 'epoch': 4.52}\n",
      "{'loss': 0.4266, 'grad_norm': 34.2796745300293, 'learning_rate': 6.983240223463688e-07, 'epoch': 4.55}\n",
      "{'loss': 0.421, 'grad_norm': 27.652929306030273, 'learning_rate': 6.424581005586592e-07, 'epoch': 4.59}\n",
      "{'loss': 0.435, 'grad_norm': 13.497071266174316, 'learning_rate': 5.865921787709498e-07, 'epoch': 4.62}\n",
      "{'loss': 0.4563, 'grad_norm': 10.006491661071777, 'learning_rate': 5.307262569832403e-07, 'epoch': 4.66}\n",
      "{'loss': 0.46, 'grad_norm': 13.232368469238281, 'learning_rate': 4.7486033519553073e-07, 'epoch': 4.7}\n",
      "{'loss': 0.5557, 'grad_norm': 94.16543579101562, 'learning_rate': 4.1899441340782126e-07, 'epoch': 4.73}\n",
      "{'loss': 0.2943, 'grad_norm': 24.846567153930664, 'learning_rate': 3.631284916201118e-07, 'epoch': 4.77}\n",
      "{'loss': 0.4377, 'grad_norm': 10.229569435119629, 'learning_rate': 3.0726256983240227e-07, 'epoch': 4.8}\n",
      "{'loss': 0.4631, 'grad_norm': 45.784629821777344, 'learning_rate': 2.5139664804469275e-07, 'epoch': 4.84}\n",
      "{'loss': 0.3802, 'grad_norm': 67.61434173583984, 'learning_rate': 1.9553072625698325e-07, 'epoch': 4.87}\n",
      "{'loss': 0.4616, 'grad_norm': 20.680566787719727, 'learning_rate': 1.3966480446927375e-07, 'epoch': 4.91}\n",
      "{'loss': 0.4584, 'grad_norm': 33.03611373901367, 'learning_rate': 8.379888268156426e-08, 'epoch': 4.95}\n",
      "{'loss': 0.5023, 'grad_norm': 16.806446075439453, 'learning_rate': 2.793296089385475e-08, 'epoch': 4.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f69f4d24d448f1bdbf88fd12089c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6474334001541138, 'eval_accuracy': 0.7275985663082437, 'eval_macro_f1': 0.7274725274725274, 'eval_weighted_f1': 0.7275145404177662, 'eval_runtime': 4.6329, 'eval_samples_per_second': 120.444, 'eval_steps_per_second': 15.109, 'epoch': 5.0}\n",
      "{'train_runtime': 580.5651, 'train_samples_per_second': 19.223, 'train_steps_per_second': 2.403, 'train_loss': 0.5677633374395337, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    " # Define the compute_metrics function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average='macro')\n",
    "    weighted_f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'weighted_f1': weighted_f1\n",
    "    }\n",
    "\n",
    "class TrainMetricsLogger(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            print(f\"Epoch: {state.epoch}, Training Metrics: {logs}\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',     # Evaluate every epoch\n",
    "    num_train_epochs=7,              # Number of epochs\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=8,   # Batch size for training\n",
    "    per_device_eval_batch_size=8,    # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps\n",
    "    weight_decay=0.05,               # Strength of weight decay\n",
    "    logging_dir='./logs',            # Directory for logs\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy='epoch',\n",
    ")\n",
    " \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3677492506417f938f8440acfc6e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2443 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7125, 'grad_norm': 1.3030606508255005, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.03}\n",
      "{'loss': 0.7206, 'grad_norm': 6.668478965759277, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.06}\n",
      "{'loss': 0.7123, 'grad_norm': 5.97066593170166, 'learning_rate': 3e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7201, 'grad_norm': 3.996624231338501, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.11}\n",
      "{'loss': 0.694, 'grad_norm': 1.6091792583465576, 'learning_rate': 5e-06, 'epoch': 0.14}\n",
      "{'loss': 0.6923, 'grad_norm': 3.787095308303833, 'learning_rate': 6e-06, 'epoch': 0.17}\n",
      "{'loss': 0.7364, 'grad_norm': 2.7237818241119385, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.2}\n",
      "{'loss': 0.6905, 'grad_norm': 3.586463212966919, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.23}\n",
      "{'loss': 0.7154, 'grad_norm': 3.5877699851989746, 'learning_rate': 9e-06, 'epoch': 0.26}\n",
      "{'loss': 0.7155, 'grad_norm': 8.306807518005371, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 0.6733, 'grad_norm': 2.8748037815093994, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.32}\n",
      "{'loss': 0.6883, 'grad_norm': 2.6293234825134277, 'learning_rate': 1.2e-05, 'epoch': 0.34}\n",
      "{'loss': 0.6728, 'grad_norm': 4.016718864440918, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.37}\n",
      "{'loss': 0.7068, 'grad_norm': 1.9554176330566406, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.4}\n",
      "{'loss': 0.7179, 'grad_norm': 2.987267255783081, 'learning_rate': 1.5e-05, 'epoch': 0.43}\n",
      "{'loss': 0.6915, 'grad_norm': 5.476060390472412, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.46}\n",
      "{'loss': 0.7098, 'grad_norm': 4.078718185424805, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.49}\n",
      "{'loss': 0.7012, 'grad_norm': 1.739546537399292, 'learning_rate': 1.8e-05, 'epoch': 0.52}\n",
      "{'loss': 0.6686, 'grad_norm': 2.164590358734131, 'learning_rate': 1.9e-05, 'epoch': 0.54}\n",
      "{'loss': 0.6919, 'grad_norm': 3.449066638946533, 'learning_rate': 2e-05, 'epoch': 0.57}\n",
      "{'loss': 0.6822, 'grad_norm': 3.133960723876953, 'learning_rate': 2.1e-05, 'epoch': 0.6}\n",
      "{'loss': 0.6897, 'grad_norm': 3.609698534011841, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.63}\n",
      "{'loss': 0.6481, 'grad_norm': 5.793687343597412, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.66}\n",
      "{'loss': 0.6863, 'grad_norm': 14.305705070495605, 'learning_rate': 2.4e-05, 'epoch': 0.69}\n",
      "{'loss': 0.6293, 'grad_norm': 9.594146728515625, 'learning_rate': 2.5e-05, 'epoch': 0.72}\n",
      "{'loss': 0.5795, 'grad_norm': 32.237144470214844, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.74}\n",
      "{'loss': 0.6491, 'grad_norm': 5.483591079711914, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.77}\n",
      "{'loss': 0.6035, 'grad_norm': 9.82442855834961, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.8}\n",
      "{'loss': 0.637, 'grad_norm': 2.0020039081573486, 'learning_rate': 2.9e-05, 'epoch': 0.83}\n",
      "{'loss': 0.8263, 'grad_norm': 9.50721263885498, 'learning_rate': 3e-05, 'epoch': 0.86}\n",
      "{'loss': 0.7893, 'grad_norm': 2.6972150802612305, 'learning_rate': 3.1e-05, 'epoch': 0.89}\n",
      "{'loss': 0.671, 'grad_norm': 5.345796585083008, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.92}\n",
      "{'loss': 0.7127, 'grad_norm': 5.082127094268799, 'learning_rate': 3.3e-05, 'epoch': 0.95}\n",
      "{'loss': 0.6887, 'grad_norm': 9.740767478942871, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9903f7be9a47f1adc9d1d0a1dd7737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6855587363243103, 'eval_accuracy': 0.5869565217391305, 'eval_macro_f1': 0.50364104993968, 'eval_weighted_f1': 0.5179237022481571, 'eval_runtime': 5.1152, 'eval_samples_per_second': 116.905, 'eval_steps_per_second': 14.662, 'epoch': 1.0}\n",
      "{'loss': 0.7601, 'grad_norm': 4.96051549911499, 'learning_rate': 3.5e-05, 'epoch': 1.0}\n",
      "{'loss': 0.6926, 'grad_norm': 5.489762306213379, 'learning_rate': 3.6e-05, 'epoch': 1.03}\n",
      "{'loss': 0.7079, 'grad_norm': 3.0916621685028076, 'learning_rate': 3.7e-05, 'epoch': 1.06}\n",
      "{'loss': 0.6184, 'grad_norm': 23.012964248657227, 'learning_rate': 3.8e-05, 'epoch': 1.09}\n",
      "{'loss': 0.6185, 'grad_norm': 130.84742736816406, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.12}\n",
      "{'loss': 0.7675, 'grad_norm': 3.9598336219787598, 'learning_rate': 4e-05, 'epoch': 1.15}\n",
      "{'loss': 0.7256, 'grad_norm': 6.200557231903076, 'learning_rate': 4.1e-05, 'epoch': 1.17}\n",
      "{'loss': 0.715, 'grad_norm': 3.0235562324523926, 'learning_rate': 4.2e-05, 'epoch': 1.2}\n",
      "{'loss': 0.7432, 'grad_norm': 4.675146102905273, 'learning_rate': 4.3e-05, 'epoch': 1.23}\n",
      "{'loss': 0.6704, 'grad_norm': 8.214797973632812, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.26}\n",
      "{'loss': 0.6278, 'grad_norm': 12.840496063232422, 'learning_rate': 4.5e-05, 'epoch': 1.29}\n",
      "{'loss': 0.6289, 'grad_norm': 14.01932144165039, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.32}\n",
      "{'loss': 0.6645, 'grad_norm': 27.512004852294922, 'learning_rate': 4.7e-05, 'epoch': 1.35}\n",
      "{'loss': 0.5412, 'grad_norm': 8.698896408081055, 'learning_rate': 4.8e-05, 'epoch': 1.38}\n",
      "{'loss': 0.7434, 'grad_norm': 12.170333862304688, 'learning_rate': 4.9e-05, 'epoch': 1.4}\n",
      "{'loss': 0.5869, 'grad_norm': 13.677861213684082, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
      "{'loss': 0.6273, 'grad_norm': 4.255396842956543, 'learning_rate': 4.974266598044261e-05, 'epoch': 1.46}\n",
      "{'loss': 0.5393, 'grad_norm': 4.486106872558594, 'learning_rate': 4.948533196088523e-05, 'epoch': 1.49}\n",
      "{'loss': 0.8749, 'grad_norm': 5.410292625427246, 'learning_rate': 4.922799794132785e-05, 'epoch': 1.52}\n",
      "{'loss': 0.587, 'grad_norm': 8.938919067382812, 'learning_rate': 4.897066392177046e-05, 'epoch': 1.55}\n",
      "{'loss': 0.5625, 'grad_norm': 12.052271842956543, 'learning_rate': 4.871332990221307e-05, 'epoch': 1.58}\n",
      "{'loss': 0.6799, 'grad_norm': 18.1849422454834, 'learning_rate': 4.845599588265569e-05, 'epoch': 1.6}\n",
      "{'loss': 0.609, 'grad_norm': 4.549025535583496, 'learning_rate': 4.8198661863098306e-05, 'epoch': 1.63}\n",
      "{'loss': 0.7129, 'grad_norm': 2.013150215148926, 'learning_rate': 4.794132784354092e-05, 'epoch': 1.66}\n",
      "{'loss': 0.6617, 'grad_norm': 3.689992904663086, 'learning_rate': 4.768399382398353e-05, 'epoch': 1.69}\n",
      "{'loss': 0.7081, 'grad_norm': 35.899410247802734, 'learning_rate': 4.742665980442615e-05, 'epoch': 1.72}\n",
      "{'loss': 0.7288, 'grad_norm': 3.4579594135284424, 'learning_rate': 4.716932578486876e-05, 'epoch': 1.75}\n",
      "{'loss': 0.6225, 'grad_norm': 12.034356117248535, 'learning_rate': 4.6911991765311374e-05, 'epoch': 1.78}\n",
      "{'loss': 0.6282, 'grad_norm': 15.131932258605957, 'learning_rate': 4.665465774575399e-05, 'epoch': 1.81}\n",
      "{'loss': 0.6004, 'grad_norm': 17.71686363220215, 'learning_rate': 4.639732372619661e-05, 'epoch': 1.83}\n",
      "{'loss': 0.6149, 'grad_norm': 10.787986755371094, 'learning_rate': 4.613998970663922e-05, 'epoch': 1.86}\n",
      "{'loss': 0.6868, 'grad_norm': 12.640347480773926, 'learning_rate': 4.588265568708183e-05, 'epoch': 1.89}\n",
      "{'loss': 0.6653, 'grad_norm': 7.884413242340088, 'learning_rate': 4.562532166752445e-05, 'epoch': 1.92}\n",
      "{'loss': 0.7187, 'grad_norm': 8.361912727355957, 'learning_rate': 4.5367987647967067e-05, 'epoch': 1.95}\n",
      "{'loss': 0.6484, 'grad_norm': 2.394798994064331, 'learning_rate': 4.511065362840968e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b24b40999cc4831bfc1d368df639dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.596375584602356, 'eval_accuracy': 0.677257525083612, 'eval_macro_f1': 0.6720997559513493, 'eval_weighted_f1': 0.6692114052372823, 'eval_runtime': 5.1579, 'eval_samples_per_second': 115.938, 'eval_steps_per_second': 14.541, 'epoch': 2.0}\n",
      "{'loss': 0.6434, 'grad_norm': 8.792694091796875, 'learning_rate': 4.485331960885229e-05, 'epoch': 2.01}\n",
      "{'loss': 0.5433, 'grad_norm': 3.0716402530670166, 'learning_rate': 4.4595985589294906e-05, 'epoch': 2.03}\n",
      "{'loss': 0.7725, 'grad_norm': 27.828704833984375, 'learning_rate': 4.4338651569737524e-05, 'epoch': 2.06}\n",
      "{'loss': 0.6125, 'grad_norm': 3.9477920532226562, 'learning_rate': 4.4081317550180135e-05, 'epoch': 2.09}\n",
      "{'loss': 0.6178, 'grad_norm': 5.320911884307861, 'learning_rate': 4.382398353062275e-05, 'epoch': 2.12}\n",
      "{'loss': 0.5633, 'grad_norm': 9.6929931640625, 'learning_rate': 4.356664951106536e-05, 'epoch': 2.15}\n",
      "{'loss': 0.6251, 'grad_norm': 6.232438564300537, 'learning_rate': 4.330931549150798e-05, 'epoch': 2.18}\n",
      "{'loss': 0.6387, 'grad_norm': 13.999774932861328, 'learning_rate': 4.305198147195059e-05, 'epoch': 2.21}\n",
      "{'loss': 0.5827, 'grad_norm': 9.610203742980957, 'learning_rate': 4.279464745239321e-05, 'epoch': 2.23}\n",
      "{'loss': 0.5322, 'grad_norm': 20.37718391418457, 'learning_rate': 4.253731343283582e-05, 'epoch': 2.26}\n",
      "{'loss': 0.5247, 'grad_norm': 7.715915203094482, 'learning_rate': 4.227997941327844e-05, 'epoch': 2.29}\n",
      "{'loss': 0.6424, 'grad_norm': 4.922499179840088, 'learning_rate': 4.202264539372105e-05, 'epoch': 2.32}\n",
      "{'loss': 0.6229, 'grad_norm': 12.349174499511719, 'learning_rate': 4.176531137416367e-05, 'epoch': 2.35}\n",
      "{'loss': 0.6043, 'grad_norm': 7.893343448638916, 'learning_rate': 4.1507977354606284e-05, 'epoch': 2.38}\n",
      "{'loss': 0.5407, 'grad_norm': 10.525858879089355, 'learning_rate': 4.1250643335048895e-05, 'epoch': 2.41}\n",
      "{'loss': 0.6223, 'grad_norm': 13.598917961120605, 'learning_rate': 4.099330931549151e-05, 'epoch': 2.44}\n",
      "{'loss': 0.6329, 'grad_norm': 4.001143455505371, 'learning_rate': 4.0735975295934124e-05, 'epoch': 2.46}\n",
      "{'loss': 0.5544, 'grad_norm': 5.652296543121338, 'learning_rate': 4.047864127637674e-05, 'epoch': 2.49}\n",
      "{'loss': 0.56, 'grad_norm': 6.412846565246582, 'learning_rate': 4.022130725681935e-05, 'epoch': 2.52}\n",
      "{'loss': 0.5252, 'grad_norm': 13.118640899658203, 'learning_rate': 3.996397323726197e-05, 'epoch': 2.55}\n",
      "{'loss': 0.559, 'grad_norm': 10.528105735778809, 'learning_rate': 3.970663921770458e-05, 'epoch': 2.58}\n",
      "{'loss': 0.5699, 'grad_norm': 7.898210048675537, 'learning_rate': 3.94493051981472e-05, 'epoch': 2.61}\n",
      "{'loss': 0.4838, 'grad_norm': 5.8319268226623535, 'learning_rate': 3.919197117858981e-05, 'epoch': 2.64}\n",
      "{'loss': 0.5988, 'grad_norm': 7.2036943435668945, 'learning_rate': 3.893463715903243e-05, 'epoch': 2.66}\n",
      "{'loss': 0.5289, 'grad_norm': 12.77025318145752, 'learning_rate': 3.867730313947504e-05, 'epoch': 2.69}\n",
      "{'loss': 0.3498, 'grad_norm': 11.033520698547363, 'learning_rate': 3.8419969119917656e-05, 'epoch': 2.72}\n",
      "{'loss': 0.7182, 'grad_norm': 9.9641695022583, 'learning_rate': 3.8162635100360274e-05, 'epoch': 2.75}\n",
      "{'loss': 0.6486, 'grad_norm': 59.74267578125, 'learning_rate': 3.7905301080802885e-05, 'epoch': 2.78}\n",
      "{'loss': 0.7094, 'grad_norm': 5.202414035797119, 'learning_rate': 3.7647967061245496e-05, 'epoch': 2.81}\n",
      "{'loss': 0.6312, 'grad_norm': 27.762128829956055, 'learning_rate': 3.739063304168811e-05, 'epoch': 2.84}\n",
      "{'loss': 0.8447, 'grad_norm': 78.35708618164062, 'learning_rate': 3.713329902213073e-05, 'epoch': 2.87}\n",
      "{'loss': 0.5946, 'grad_norm': 19.099773406982422, 'learning_rate': 3.687596500257334e-05, 'epoch': 2.89}\n",
      "{'loss': 0.4841, 'grad_norm': 18.588077545166016, 'learning_rate': 3.661863098301595e-05, 'epoch': 2.92}\n",
      "{'loss': 0.5555, 'grad_norm': 22.950973510742188, 'learning_rate': 3.636129696345857e-05, 'epoch': 2.95}\n",
      "{'loss': 0.6693, 'grad_norm': 13.423866271972656, 'learning_rate': 3.610396294390119e-05, 'epoch': 2.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93377b45a95458fa069887c1c62fbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5461944937705994, 'eval_accuracy': 0.7240802675585284, 'eval_macro_f1': 0.7235971863891153, 'eval_weighted_f1': 0.7227856100245013, 'eval_runtime': 5.1682, 'eval_samples_per_second': 115.708, 'eval_steps_per_second': 14.512, 'epoch': 3.0}\n",
      "{'loss': 0.4853, 'grad_norm': 4.123779773712158, 'learning_rate': 3.58466289243438e-05, 'epoch': 3.01}\n",
      "{'loss': 0.5587, 'grad_norm': 20.112539291381836, 'learning_rate': 3.558929490478641e-05, 'epoch': 3.04}\n",
      "{'loss': 0.5812, 'grad_norm': 13.740710258483887, 'learning_rate': 3.533196088522903e-05, 'epoch': 3.07}\n",
      "{'loss': 0.4782, 'grad_norm': 6.862877368927002, 'learning_rate': 3.5074626865671645e-05, 'epoch': 3.09}\n",
      "{'loss': 0.637, 'grad_norm': 17.285629272460938, 'learning_rate': 3.4817292846114256e-05, 'epoch': 3.12}\n",
      "{'loss': 0.5202, 'grad_norm': 3.625974178314209, 'learning_rate': 3.4559958826556874e-05, 'epoch': 3.15}\n",
      "{'loss': 0.5559, 'grad_norm': 12.960844993591309, 'learning_rate': 3.430262480699949e-05, 'epoch': 3.18}\n",
      "{'loss': 0.5015, 'grad_norm': 12.375205993652344, 'learning_rate': 3.40452907874421e-05, 'epoch': 3.21}\n",
      "{'loss': 0.4912, 'grad_norm': 4.841257095336914, 'learning_rate': 3.3787956767884714e-05, 'epoch': 3.24}\n",
      "{'loss': 0.4537, 'grad_norm': 8.619674682617188, 'learning_rate': 3.353062274832733e-05, 'epoch': 3.27}\n",
      "{'loss': 0.4676, 'grad_norm': 2.7944142818450928, 'learning_rate': 3.327328872876995e-05, 'epoch': 3.3}\n",
      "{'loss': 0.5658, 'grad_norm': 16.73081398010254, 'learning_rate': 3.301595470921256e-05, 'epoch': 3.32}\n",
      "{'loss': 0.4934, 'grad_norm': 17.5318603515625, 'learning_rate': 3.275862068965517e-05, 'epoch': 3.35}\n",
      "{'loss': 0.7349, 'grad_norm': 4.948293209075928, 'learning_rate': 3.250128667009779e-05, 'epoch': 3.38}\n",
      "{'loss': 0.4575, 'grad_norm': 2.12629771232605, 'learning_rate': 3.2243952650540406e-05, 'epoch': 3.41}\n",
      "{'loss': 0.5292, 'grad_norm': 27.55684471130371, 'learning_rate': 3.198661863098302e-05, 'epoch': 3.44}\n",
      "{'loss': 0.4247, 'grad_norm': 3.3604001998901367, 'learning_rate': 3.172928461142563e-05, 'epoch': 3.47}\n",
      "{'loss': 0.6034, 'grad_norm': 22.087358474731445, 'learning_rate': 3.1471950591868246e-05, 'epoch': 3.5}\n",
      "{'loss': 0.4597, 'grad_norm': 25.245662689208984, 'learning_rate': 3.121461657231086e-05, 'epoch': 3.52}\n",
      "{'loss': 0.3917, 'grad_norm': 21.218290328979492, 'learning_rate': 3.0957282552753474e-05, 'epoch': 3.55}\n",
      "{'loss': 0.6307, 'grad_norm': 5.111244201660156, 'learning_rate': 3.0699948533196085e-05, 'epoch': 3.58}\n",
      "{'loss': 0.6772, 'grad_norm': 5.907938480377197, 'learning_rate': 3.0442614513638706e-05, 'epoch': 3.61}\n",
      "{'loss': 0.5112, 'grad_norm': 3.024489164352417, 'learning_rate': 3.018528049408132e-05, 'epoch': 3.64}\n",
      "{'loss': 0.4386, 'grad_norm': 59.42092514038086, 'learning_rate': 2.992794647452393e-05, 'epoch': 3.67}\n",
      "{'loss': 0.4702, 'grad_norm': 34.49700927734375, 'learning_rate': 2.9670612454966546e-05, 'epoch': 3.7}\n",
      "{'loss': 0.6422, 'grad_norm': 20.117473602294922, 'learning_rate': 2.9413278435409163e-05, 'epoch': 3.72}\n",
      "{'loss': 0.3799, 'grad_norm': 8.585596084594727, 'learning_rate': 2.9155944415851778e-05, 'epoch': 3.75}\n",
      "{'loss': 0.5506, 'grad_norm': 2.670463800430298, 'learning_rate': 2.889861039629439e-05, 'epoch': 3.78}\n",
      "{'loss': 0.6525, 'grad_norm': 8.174631118774414, 'learning_rate': 2.864127637673701e-05, 'epoch': 3.81}\n",
      "{'loss': 0.4517, 'grad_norm': 22.7640380859375, 'learning_rate': 2.838394235717962e-05, 'epoch': 3.84}\n",
      "{'loss': 0.4747, 'grad_norm': 4.766795635223389, 'learning_rate': 2.8126608337622235e-05, 'epoch': 3.87}\n",
      "{'loss': 0.3963, 'grad_norm': 13.1107177734375, 'learning_rate': 2.7869274318064846e-05, 'epoch': 3.9}\n",
      "{'loss': 0.3977, 'grad_norm': 12.29783821105957, 'learning_rate': 2.7611940298507467e-05, 'epoch': 3.93}\n",
      "{'loss': 0.5003, 'grad_norm': 7.916053295135498, 'learning_rate': 2.7354606278950078e-05, 'epoch': 3.95}\n",
      "{'loss': 0.4733, 'grad_norm': 90.88389587402344, 'learning_rate': 2.7097272259392692e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208d0dbe6c644e29a196c81d33d4df34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5944318771362305, 'eval_accuracy': 0.7625418060200669, 'eval_macro_f1': 0.7621587102412135, 'eval_weighted_f1': 0.7628291278542069, 'eval_runtime': 5.0834, 'eval_samples_per_second': 117.639, 'eval_steps_per_second': 14.754, 'epoch': 4.0}\n",
      "{'loss': 0.5712, 'grad_norm': 10.345951080322266, 'learning_rate': 2.6839938239835306e-05, 'epoch': 4.01}\n",
      "{'loss': 0.4004, 'grad_norm': 2.945734977722168, 'learning_rate': 2.6582604220277924e-05, 'epoch': 4.04}\n",
      "{'loss': 0.3944, 'grad_norm': 45.80988693237305, 'learning_rate': 2.6325270200720535e-05, 'epoch': 4.07}\n",
      "{'loss': 0.5574, 'grad_norm': 408.3661193847656, 'learning_rate': 2.606793618116315e-05, 'epoch': 4.1}\n",
      "{'loss': 0.6178, 'grad_norm': 4.739035129547119, 'learning_rate': 2.5810602161605767e-05, 'epoch': 4.13}\n",
      "{'loss': 0.4358, 'grad_norm': 15.261650085449219, 'learning_rate': 2.555326814204838e-05, 'epoch': 4.15}\n",
      "{'loss': 0.4948, 'grad_norm': 4.0554351806640625, 'learning_rate': 2.5295934122490996e-05, 'epoch': 4.18}\n",
      "{'loss': 0.373, 'grad_norm': 5.408343315124512, 'learning_rate': 2.5038600102933607e-05, 'epoch': 4.21}\n",
      "{'loss': 0.444, 'grad_norm': 7.515415668487549, 'learning_rate': 2.4781266083376224e-05, 'epoch': 4.24}\n",
      "{'loss': 0.4483, 'grad_norm': 27.861907958984375, 'learning_rate': 2.452393206381884e-05, 'epoch': 4.27}\n",
      "{'loss': 0.4748, 'grad_norm': 18.784988403320312, 'learning_rate': 2.4266598044261453e-05, 'epoch': 4.3}\n",
      "{'loss': 0.5261, 'grad_norm': 25.343259811401367, 'learning_rate': 2.4009264024704067e-05, 'epoch': 4.33}\n",
      "{'loss': 0.634, 'grad_norm': 11.215039253234863, 'learning_rate': 2.375193000514668e-05, 'epoch': 4.36}\n",
      "{'loss': 0.3558, 'grad_norm': 8.238419532775879, 'learning_rate': 2.3494595985589296e-05, 'epoch': 4.38}\n",
      "{'loss': 0.4669, 'grad_norm': 7.560523986816406, 'learning_rate': 2.3237261966031913e-05, 'epoch': 4.41}\n",
      "{'loss': 0.3084, 'grad_norm': 2.9967453479766846, 'learning_rate': 2.2979927946474524e-05, 'epoch': 4.44}\n",
      "{'loss': 0.2993, 'grad_norm': 20.776777267456055, 'learning_rate': 2.2722593926917142e-05, 'epoch': 4.47}\n",
      "{'loss': 0.4373, 'grad_norm': 9.37909984588623, 'learning_rate': 2.2465259907359753e-05, 'epoch': 4.5}\n",
      "{'loss': 0.5126, 'grad_norm': 8.04392147064209, 'learning_rate': 2.220792588780237e-05, 'epoch': 4.53}\n",
      "{'loss': 0.4025, 'grad_norm': 6.744488716125488, 'learning_rate': 2.195059186824498e-05, 'epoch': 4.56}\n",
      "{'loss': 0.4253, 'grad_norm': 3.3939881324768066, 'learning_rate': 2.16932578486876e-05, 'epoch': 4.58}\n",
      "{'loss': 0.3993, 'grad_norm': 70.3879623413086, 'learning_rate': 2.143592382913021e-05, 'epoch': 4.61}\n",
      "{'loss': 0.6182, 'grad_norm': 41.605777740478516, 'learning_rate': 2.1178589809572828e-05, 'epoch': 4.64}\n",
      "{'loss': 0.5571, 'grad_norm': 4.3087849617004395, 'learning_rate': 2.092125579001544e-05, 'epoch': 4.67}\n",
      "{'loss': 0.3546, 'grad_norm': 22.007217407226562, 'learning_rate': 2.0663921770458056e-05, 'epoch': 4.7}\n",
      "{'loss': 0.4293, 'grad_norm': 18.212078094482422, 'learning_rate': 2.040658775090067e-05, 'epoch': 4.73}\n",
      "{'loss': 0.4389, 'grad_norm': 5.256497859954834, 'learning_rate': 2.0149253731343285e-05, 'epoch': 4.76}\n",
      "{'loss': 0.4018, 'grad_norm': 13.747781753540039, 'learning_rate': 1.98919197117859e-05, 'epoch': 4.79}\n",
      "{'loss': 0.4033, 'grad_norm': 8.131314277648926, 'learning_rate': 1.9634585692228514e-05, 'epoch': 4.81}\n",
      "{'loss': 0.3701, 'grad_norm': 2.1207058429718018, 'learning_rate': 1.9377251672671128e-05, 'epoch': 4.84}\n",
      "{'loss': 0.4877, 'grad_norm': 19.21648406982422, 'learning_rate': 1.9119917653113742e-05, 'epoch': 4.87}\n",
      "{'loss': 0.5495, 'grad_norm': 12.178191184997559, 'learning_rate': 1.8862583633556357e-05, 'epoch': 4.9}\n",
      "{'loss': 0.4408, 'grad_norm': 13.185393333435059, 'learning_rate': 1.860524961399897e-05, 'epoch': 4.93}\n",
      "{'loss': 0.4533, 'grad_norm': 16.76239776611328, 'learning_rate': 1.8347915594441585e-05, 'epoch': 4.96}\n",
      "{'loss': 0.4411, 'grad_norm': 5.990844249725342, 'learning_rate': 1.80905815748842e-05, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a9a1bf839b4748af9de4803af7edec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5283880829811096, 'eval_accuracy': 0.7558528428093646, 'eval_macro_f1': 0.7556314375279893, 'eval_weighted_f1': 0.7551148252047802, 'eval_runtime': 5.1548, 'eval_samples_per_second': 116.008, 'eval_steps_per_second': 14.55, 'epoch': 5.0}\n",
      "{'loss': 0.4618, 'grad_norm': 14.869614601135254, 'learning_rate': 1.7833247555326814e-05, 'epoch': 5.01}\n",
      "{'loss': 0.4118, 'grad_norm': 7.133627414703369, 'learning_rate': 1.7575913535769428e-05, 'epoch': 5.04}\n",
      "{'loss': 0.4594, 'grad_norm': 3.9304745197296143, 'learning_rate': 1.7318579516212042e-05, 'epoch': 5.07}\n",
      "{'loss': 0.3852, 'grad_norm': 4.245253562927246, 'learning_rate': 1.706124549665466e-05, 'epoch': 5.1}\n",
      "{'loss': 0.4606, 'grad_norm': 1.6010116338729858, 'learning_rate': 1.6803911477097274e-05, 'epoch': 5.13}\n",
      "{'loss': 0.3697, 'grad_norm': 1.6295545101165771, 'learning_rate': 1.654657745753989e-05, 'epoch': 5.16}\n",
      "{'loss': 0.3384, 'grad_norm': 4.387369155883789, 'learning_rate': 1.6289243437982503e-05, 'epoch': 5.19}\n",
      "{'loss': 0.4381, 'grad_norm': 20.343000411987305, 'learning_rate': 1.6031909418425117e-05, 'epoch': 5.21}\n",
      "{'loss': 0.3723, 'grad_norm': 5.300678730010986, 'learning_rate': 1.577457539886773e-05, 'epoch': 5.24}\n",
      "{'loss': 0.3184, 'grad_norm': 45.65872573852539, 'learning_rate': 1.5517241379310346e-05, 'epoch': 5.27}\n",
      "{'loss': 0.4582, 'grad_norm': 1.69623601436615, 'learning_rate': 1.525990735975296e-05, 'epoch': 5.3}\n",
      "{'loss': 0.3891, 'grad_norm': 17.25442123413086, 'learning_rate': 1.5002573340195574e-05, 'epoch': 5.33}\n",
      "{'loss': 0.3199, 'grad_norm': 2.9143574237823486, 'learning_rate': 1.4745239320638187e-05, 'epoch': 5.36}\n",
      "{'loss': 0.4764, 'grad_norm': 0.8914383053779602, 'learning_rate': 1.4487905301080803e-05, 'epoch': 5.39}\n",
      "{'loss': 0.3682, 'grad_norm': 5.301545143127441, 'learning_rate': 1.4230571281523419e-05, 'epoch': 5.42}\n",
      "{'loss': 0.4886, 'grad_norm': 3.8202860355377197, 'learning_rate': 1.3973237261966032e-05, 'epoch': 5.44}\n",
      "{'loss': 0.4521, 'grad_norm': 10.035573959350586, 'learning_rate': 1.3715903242408648e-05, 'epoch': 5.47}\n",
      "{'loss': 0.443, 'grad_norm': 15.156124114990234, 'learning_rate': 1.3458569222851262e-05, 'epoch': 5.5}\n",
      "{'loss': 0.3465, 'grad_norm': 18.416446685791016, 'learning_rate': 1.3201235203293876e-05, 'epoch': 5.53}\n",
      "{'loss': 0.5293, 'grad_norm': 9.552374839782715, 'learning_rate': 1.294390118373649e-05, 'epoch': 5.56}\n",
      "{'loss': 0.3753, 'grad_norm': 13.996952056884766, 'learning_rate': 1.2686567164179105e-05, 'epoch': 5.59}\n",
      "{'loss': 0.3486, 'grad_norm': 24.500900268554688, 'learning_rate': 1.242923314462172e-05, 'epoch': 5.62}\n",
      "{'loss': 0.2971, 'grad_norm': 57.72826385498047, 'learning_rate': 1.2171899125064335e-05, 'epoch': 5.64}\n",
      "{'loss': 0.4386, 'grad_norm': 0.7072180509567261, 'learning_rate': 1.191456510550695e-05, 'epoch': 5.67}\n",
      "{'loss': 0.3985, 'grad_norm': 12.328940391540527, 'learning_rate': 1.1657231085949564e-05, 'epoch': 5.7}\n",
      "{'loss': 0.5105, 'grad_norm': 18.723413467407227, 'learning_rate': 1.1399897066392178e-05, 'epoch': 5.73}\n",
      "{'loss': 0.3472, 'grad_norm': 4.027052402496338, 'learning_rate': 1.1142563046834792e-05, 'epoch': 5.76}\n",
      "{'loss': 0.3147, 'grad_norm': 56.27724075317383, 'learning_rate': 1.0885229027277407e-05, 'epoch': 5.79}\n",
      "{'loss': 0.5042, 'grad_norm': 32.87952423095703, 'learning_rate': 1.0627895007720021e-05, 'epoch': 5.82}\n",
      "{'loss': 0.4173, 'grad_norm': 2.0288946628570557, 'learning_rate': 1.0370560988162635e-05, 'epoch': 5.85}\n",
      "{'loss': 0.4926, 'grad_norm': 27.440086364746094, 'learning_rate': 1.011322696860525e-05, 'epoch': 5.87}\n",
      "{'loss': 0.4276, 'grad_norm': 10.556384086608887, 'learning_rate': 9.855892949047866e-06, 'epoch': 5.9}\n",
      "{'loss': 0.4643, 'grad_norm': 1.4482567310333252, 'learning_rate': 9.59855892949048e-06, 'epoch': 5.93}\n",
      "{'loss': 0.3767, 'grad_norm': 27.753944396972656, 'learning_rate': 9.341224909933094e-06, 'epoch': 5.96}\n",
      "{'loss': 0.3692, 'grad_norm': 10.587130546569824, 'learning_rate': 9.083890890375708e-06, 'epoch': 5.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728bf808c4ae4bcbae0711445224f792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6099260449409485, 'eval_accuracy': 0.7525083612040134, 'eval_macro_f1': 0.7523726385531382, 'eval_weighted_f1': 0.7519654706005124, 'eval_runtime': 5.05, 'eval_samples_per_second': 118.415, 'eval_steps_per_second': 14.851, 'epoch': 6.0}\n",
      "{'loss': 0.281, 'grad_norm': 12.648601531982422, 'learning_rate': 8.826556870818323e-06, 'epoch': 6.02}\n",
      "{'loss': 0.3675, 'grad_norm': 6.473410129547119, 'learning_rate': 8.569222851260937e-06, 'epoch': 6.05}\n",
      "{'loss': 0.1967, 'grad_norm': 60.51615905761719, 'learning_rate': 8.311888831703551e-06, 'epoch': 6.07}\n",
      "{'loss': 0.2839, 'grad_norm': 0.8277703523635864, 'learning_rate': 8.054554812146166e-06, 'epoch': 6.1}\n",
      "{'loss': 0.4767, 'grad_norm': 0.8592621684074402, 'learning_rate': 7.79722079258878e-06, 'epoch': 6.13}\n",
      "{'loss': 0.5279, 'grad_norm': 32.45942306518555, 'learning_rate': 7.539886773031394e-06, 'epoch': 6.16}\n",
      "{'loss': 0.3238, 'grad_norm': 8.864876747131348, 'learning_rate': 7.282552753474009e-06, 'epoch': 6.19}\n",
      "{'loss': 0.2511, 'grad_norm': 2.386958122253418, 'learning_rate': 7.0252187339166245e-06, 'epoch': 6.22}\n",
      "{'loss': 0.3689, 'grad_norm': 2.423797845840454, 'learning_rate': 6.767884714359239e-06, 'epoch': 6.25}\n",
      "{'loss': 0.2866, 'grad_norm': 12.699362754821777, 'learning_rate': 6.510550694801854e-06, 'epoch': 6.28}\n",
      "{'loss': 0.429, 'grad_norm': 21.34347915649414, 'learning_rate': 6.253216675244468e-06, 'epoch': 6.3}\n",
      "{'loss': 0.2155, 'grad_norm': 18.310592651367188, 'learning_rate': 5.9958826556870826e-06, 'epoch': 6.33}\n",
      "{'loss': 0.2821, 'grad_norm': 7.57588005065918, 'learning_rate': 5.738548636129697e-06, 'epoch': 6.36}\n",
      "{'loss': 0.5072, 'grad_norm': 7.876901626586914, 'learning_rate': 5.481214616572311e-06, 'epoch': 6.39}\n",
      "{'loss': 0.2672, 'grad_norm': 6.219150066375732, 'learning_rate': 5.2238805970149255e-06, 'epoch': 6.42}\n",
      "{'loss': 0.3505, 'grad_norm': 21.119714736938477, 'learning_rate': 4.96654657745754e-06, 'epoch': 6.45}\n",
      "{'loss': 0.2538, 'grad_norm': 20.56787109375, 'learning_rate': 4.709212557900155e-06, 'epoch': 6.48}\n",
      "{'loss': 0.3261, 'grad_norm': 1.0304739475250244, 'learning_rate': 4.451878538342769e-06, 'epoch': 6.5}\n",
      "{'loss': 0.4476, 'grad_norm': 39.663082122802734, 'learning_rate': 4.1945445187853835e-06, 'epoch': 6.53}\n",
      "{'loss': 0.6097, 'grad_norm': 21.121042251586914, 'learning_rate': 3.937210499227998e-06, 'epoch': 6.56}\n",
      "{'loss': 0.4652, 'grad_norm': 13.208768844604492, 'learning_rate': 3.6798764796706125e-06, 'epoch': 6.59}\n",
      "{'loss': 0.3475, 'grad_norm': 7.767789840698242, 'learning_rate': 3.422542460113227e-06, 'epoch': 6.62}\n",
      "{'loss': 0.3846, 'grad_norm': 18.316152572631836, 'learning_rate': 3.165208440555842e-06, 'epoch': 6.65}\n",
      "{'loss': 0.31, 'grad_norm': 1.1182116270065308, 'learning_rate': 2.9078744209984563e-06, 'epoch': 6.68}\n",
      "{'loss': 0.3524, 'grad_norm': 2.2333545684814453, 'learning_rate': 2.6505404014410706e-06, 'epoch': 6.7}\n",
      "{'loss': 0.3636, 'grad_norm': 20.9735050201416, 'learning_rate': 2.393206381883685e-06, 'epoch': 6.73}\n",
      "{'loss': 0.3282, 'grad_norm': 2.6565966606140137, 'learning_rate': 2.1358723623262996e-06, 'epoch': 6.76}\n",
      "{'loss': 0.334, 'grad_norm': 31.420289993286133, 'learning_rate': 1.8785383427689141e-06, 'epoch': 6.79}\n",
      "{'loss': 0.1399, 'grad_norm': 3.1081631183624268, 'learning_rate': 1.6212043232115284e-06, 'epoch': 6.82}\n",
      "{'loss': 0.2091, 'grad_norm': 4.281017780303955, 'learning_rate': 1.3638703036541431e-06, 'epoch': 6.85}\n",
      "{'loss': 0.3107, 'grad_norm': 9.33066463470459, 'learning_rate': 1.1065362840967577e-06, 'epoch': 6.88}\n",
      "{'loss': 0.3847, 'grad_norm': 19.53246307373047, 'learning_rate': 8.492022645393722e-07, 'epoch': 6.91}\n",
      "{'loss': 0.4931, 'grad_norm': 5.8567681312561035, 'learning_rate': 5.918682449819866e-07, 'epoch': 6.93}\n",
      "{'loss': 0.4697, 'grad_norm': 26.144575119018555, 'learning_rate': 3.3453422542460114e-07, 'epoch': 6.96}\n",
      "{'loss': 0.2395, 'grad_norm': 3.4515738487243652, 'learning_rate': 7.720020586721566e-08, 'epoch': 6.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9525c9b2865d43d39b5362bb2959003f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7229607105255127, 'eval_accuracy': 0.7692307692307693, 'eval_macro_f1': 0.7692075353499195, 'eval_weighted_f1': 0.7693701725158679, 'eval_runtime': 5.2156, 'eval_samples_per_second': 114.656, 'eval_steps_per_second': 14.38, 'epoch': 7.0}\n",
      "{'train_runtime': 992.2913, 'train_samples_per_second': 19.682, 'train_steps_per_second': 2.462, 'train_loss': 0.5255951188501646, 'epoch': 7.0}\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    " # Define the compute_metrics function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average='macro')\n",
    "    weighted_f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'weighted_f1': weighted_f1\n",
    "    }\n",
    "\n",
    "class TrainMetricsLogger(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            print(f\"Epoch: {state.epoch}, Training Metrics: {logs}\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',     # Evaluate every epoch\n",
    "    num_train_epochs=7,              # Number of epochs\n",
    "    per_device_train_batch_size=8,   # Batch size for training\n",
    "    per_device_eval_batch_size=8,    # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps\n",
    "    weight_decay=0.05,               # Strength of weight decay\n",
    "    logging_dir='./logs',            # Directory for logs\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy='epoch',\n",
    ")\n",
    " \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae29c26c323d40c48cbfa56c69ffbd3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2443 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7055, 'grad_norm': 2.4591064453125, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.03}\n",
      "{'loss': 0.698, 'grad_norm': 5.322478294372559, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.06}\n",
      "{'loss': 0.7023, 'grad_norm': 4.648119926452637, 'learning_rate': 3e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6991, 'grad_norm': 2.17541241645813, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.11}\n",
      "{'loss': 0.7008, 'grad_norm': 2.655975103378296, 'learning_rate': 5e-06, 'epoch': 0.14}\n",
      "{'loss': 0.6885, 'grad_norm': 4.5047125816345215, 'learning_rate': 6e-06, 'epoch': 0.17}\n",
      "{'loss': 0.7106, 'grad_norm': 1.4660624265670776, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.2}\n",
      "{'loss': 0.6978, 'grad_norm': 2.2469043731689453, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.23}\n",
      "{'loss': 0.688, 'grad_norm': 2.2223477363586426, 'learning_rate': 9e-06, 'epoch': 0.26}\n",
      "{'loss': 0.688, 'grad_norm': 6.558040142059326, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 0.697, 'grad_norm': 2.822620153427124, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.32}\n",
      "{'loss': 0.7062, 'grad_norm': 2.5835306644439697, 'learning_rate': 1.2e-05, 'epoch': 0.34}\n",
      "{'loss': 0.69, 'grad_norm': 5.11615514755249, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.37}\n",
      "{'loss': 0.6913, 'grad_norm': 2.2894976139068604, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.4}\n",
      "{'loss': 0.6898, 'grad_norm': 2.1528513431549072, 'learning_rate': 1.5e-05, 'epoch': 0.43}\n",
      "{'loss': 0.6877, 'grad_norm': 4.175701141357422, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.46}\n",
      "{'loss': 0.6608, 'grad_norm': 2.195838212966919, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.49}\n",
      "{'loss': 0.6286, 'grad_norm': 3.2831361293792725, 'learning_rate': 1.8e-05, 'epoch': 0.52}\n",
      "{'loss': 0.5803, 'grad_norm': 2.8758327960968018, 'learning_rate': 1.9e-05, 'epoch': 0.54}\n",
      "{'loss': 0.6061, 'grad_norm': 2.0915591716766357, 'learning_rate': 2e-05, 'epoch': 0.57}\n",
      "{'loss': 0.6968, 'grad_norm': 2.7694411277770996, 'learning_rate': 2.1e-05, 'epoch': 0.6}\n",
      "{'loss': 0.6304, 'grad_norm': 3.1186723709106445, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.63}\n",
      "{'loss': 0.5919, 'grad_norm': 3.660353660583496, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.66}\n",
      "{'loss': 0.6034, 'grad_norm': 4.311688423156738, 'learning_rate': 2.4e-05, 'epoch': 0.69}\n",
      "{'loss': 0.4731, 'grad_norm': 2.247156858444214, 'learning_rate': 2.5e-05, 'epoch': 0.72}\n",
      "{'loss': 0.6291, 'grad_norm': 4.322746276855469, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.74}\n",
      "{'loss': 0.5965, 'grad_norm': 2.6762595176696777, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.77}\n",
      "{'loss': 0.6838, 'grad_norm': 2.2735512256622314, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.8}\n",
      "{'loss': 0.623, 'grad_norm': 4.2167439460754395, 'learning_rate': 2.9e-05, 'epoch': 0.83}\n",
      "{'loss': 0.772, 'grad_norm': 2.5165960788726807, 'learning_rate': 3e-05, 'epoch': 0.86}\n",
      "{'loss': 0.904, 'grad_norm': 3.4852592945098877, 'learning_rate': 3.1e-05, 'epoch': 0.89}\n",
      "{'loss': 0.7207, 'grad_norm': 1.9497625827789307, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.92}\n",
      "{'loss': 0.7179, 'grad_norm': 2.4835877418518066, 'learning_rate': 3.3e-05, 'epoch': 0.95}\n",
      "{'loss': 0.6738, 'grad_norm': 2.7224841117858887, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c74b6574c3748c99bdd654e644b5ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7060222029685974, 'eval_accuracy': 0.46488294314381273, 'eval_macro_f1': 0.317351598173516, 'eval_weighted_f1': 0.2950626899405934, 'eval_runtime': 5.1504, 'eval_samples_per_second': 116.106, 'eval_steps_per_second': 14.562, 'epoch': 1.0}\n",
      "{'loss': 0.7443, 'grad_norm': 5.256906986236572, 'learning_rate': 3.5e-05, 'epoch': 1.0}\n",
      "{'loss': 0.6951, 'grad_norm': 1.6575927734375, 'learning_rate': 3.6e-05, 'epoch': 1.03}\n",
      "{'loss': 0.6931, 'grad_norm': 1.7412819862365723, 'learning_rate': 3.7e-05, 'epoch': 1.06}\n",
      "{'loss': 0.703, 'grad_norm': 3.2224740982055664, 'learning_rate': 3.8e-05, 'epoch': 1.09}\n",
      "{'loss': 0.7133, 'grad_norm': 4.08530855178833, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.12}\n",
      "{'loss': 0.7048, 'grad_norm': 1.4301460981369019, 'learning_rate': 4e-05, 'epoch': 1.15}\n",
      "{'loss': 0.7033, 'grad_norm': 3.069645643234253, 'learning_rate': 4.1e-05, 'epoch': 1.17}\n",
      "{'loss': 0.7094, 'grad_norm': 1.5487245321273804, 'learning_rate': 4.2e-05, 'epoch': 1.2}\n",
      "{'loss': 0.6924, 'grad_norm': 2.9179625511169434, 'learning_rate': 4.3e-05, 'epoch': 1.23}\n",
      "{'loss': 0.7155, 'grad_norm': 1.3189187049865723, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.26}\n",
      "{'loss': 0.6914, 'grad_norm': 1.3693737983703613, 'learning_rate': 4.5e-05, 'epoch': 1.29}\n",
      "{'loss': 0.7029, 'grad_norm': 1.4218714237213135, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.32}\n",
      "{'loss': 0.7041, 'grad_norm': 7.4753217697143555, 'learning_rate': 4.7e-05, 'epoch': 1.35}\n",
      "{'loss': 0.6974, 'grad_norm': 2.6058173179626465, 'learning_rate': 4.8e-05, 'epoch': 1.38}\n",
      "{'loss': 0.6731, 'grad_norm': 4.936349868774414, 'learning_rate': 4.9e-05, 'epoch': 1.4}\n",
      "{'loss': 0.7225, 'grad_norm': 5.0055155754089355, 'learning_rate': 5e-05, 'epoch': 1.43}\n",
      "{'loss': 0.7034, 'grad_norm': 2.0946860313415527, 'learning_rate': 4.974266598044261e-05, 'epoch': 1.46}\n",
      "{'loss': 0.6961, 'grad_norm': 2.5677554607391357, 'learning_rate': 4.948533196088523e-05, 'epoch': 1.49}\n",
      "{'loss': 0.7077, 'grad_norm': 1.1478242874145508, 'learning_rate': 4.922799794132785e-05, 'epoch': 1.52}\n",
      "{'loss': 0.6791, 'grad_norm': 4.027223587036133, 'learning_rate': 4.897066392177046e-05, 'epoch': 1.55}\n",
      "{'loss': 0.7089, 'grad_norm': 2.1784772872924805, 'learning_rate': 4.871332990221307e-05, 'epoch': 1.58}\n",
      "{'loss': 0.7074, 'grad_norm': 2.3717739582061768, 'learning_rate': 4.845599588265569e-05, 'epoch': 1.6}\n",
      "{'loss': 0.698, 'grad_norm': 2.5292739868164062, 'learning_rate': 4.8198661863098306e-05, 'epoch': 1.63}\n",
      "{'loss': 0.7107, 'grad_norm': 1.2976292371749878, 'learning_rate': 4.794132784354092e-05, 'epoch': 1.66}\n",
      "{'loss': 0.7219, 'grad_norm': 3.102555751800537, 'learning_rate': 4.768399382398353e-05, 'epoch': 1.69}\n",
      "{'loss': 0.711, 'grad_norm': 5.862668037414551, 'learning_rate': 4.742665980442615e-05, 'epoch': 1.72}\n",
      "{'loss': 0.7033, 'grad_norm': 6.6034932136535645, 'learning_rate': 4.716932578486876e-05, 'epoch': 1.75}\n",
      "{'loss': 0.7323, 'grad_norm': 1.0551562309265137, 'learning_rate': 4.6911991765311374e-05, 'epoch': 1.78}\n",
      "{'loss': 0.6922, 'grad_norm': 4.10377836227417, 'learning_rate': 4.665465774575399e-05, 'epoch': 1.81}\n",
      "{'loss': 0.6918, 'grad_norm': 2.6549131870269775, 'learning_rate': 4.639732372619661e-05, 'epoch': 1.83}\n",
      "{'loss': 0.6817, 'grad_norm': 2.5412662029266357, 'learning_rate': 4.613998970663922e-05, 'epoch': 1.86}\n",
      "{'loss': 0.6855, 'grad_norm': 1.3861769437789917, 'learning_rate': 4.588265568708183e-05, 'epoch': 1.89}\n",
      "{'loss': 0.681, 'grad_norm': 1.851615309715271, 'learning_rate': 4.562532166752445e-05, 'epoch': 1.92}\n",
      "{'loss': 0.7207, 'grad_norm': 6.6489996910095215, 'learning_rate': 4.5367987647967067e-05, 'epoch': 1.95}\n",
      "{'loss': 0.704, 'grad_norm': 1.2224448919296265, 'learning_rate': 4.511065362840968e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd3b9693e7d424587e5ae4e948df388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6990594267845154, 'eval_accuracy': 0.46488294314381273, 'eval_macro_f1': 0.317351598173516, 'eval_weighted_f1': 0.2950626899405934, 'eval_runtime': 5.0806, 'eval_samples_per_second': 117.703, 'eval_steps_per_second': 14.762, 'epoch': 2.0}\n",
      "{'loss': 0.6967, 'grad_norm': 5.196981906890869, 'learning_rate': 4.485331960885229e-05, 'epoch': 2.01}\n",
      "{'loss': 0.6967, 'grad_norm': 2.2718303203582764, 'learning_rate': 4.4595985589294906e-05, 'epoch': 2.03}\n",
      "{'loss': 0.6997, 'grad_norm': 3.4045960903167725, 'learning_rate': 4.4338651569737524e-05, 'epoch': 2.06}\n",
      "{'loss': 0.7111, 'grad_norm': 3.719268798828125, 'learning_rate': 4.4081317550180135e-05, 'epoch': 2.09}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 41\u001b[0m\n\u001b[1;32m     20\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     21\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m     eval_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,     \u001b[38;5;66;03m# Evaluate every epoch\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     save_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     35\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     36\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     40\u001b[0m )\n\u001b[0;32m---> 41\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/text-recommendation/.venv/lib/python3.9/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/text-recommendation/.venv/lib/python3.9/site-packages/transformers/trainer.py:2534\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2530\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[1;32m   2532\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_pre_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2534\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2538\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n",
      "File \u001b[0;32m~/Documents/text-recommendation/.venv/lib/python3.9/site-packages/accelerate/optimizer.py:178\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/text-recommendation/.venv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:137\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    136\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/text-recommendation/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/text-recommendation/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Documents/text-recommendation/.venv/lib/python3.9/site-packages/torch/optim/adamw.py:220\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    207\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    209\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    210\u001b[0m         group,\n\u001b[1;32m    211\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         state_steps,\n\u001b[1;32m    218\u001b[0m     )\n\u001b[0;32m--> 220\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Documents/text-recommendation/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/text-recommendation/.venv/lib/python3.9/site-packages/torch/optim/adamw.py:782\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    780\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 782\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/text-recommendation/.venv/lib/python3.9/site-packages/torch/optim/adamw.py:427\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    425\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    " # Define the compute_metrics function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average='macro')\n",
    "    weighted_f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'weighted_f1': weighted_f1\n",
    "    }\n",
    "\n",
    "class TrainMetricsLogger(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            print(f\"Epoch: {state.epoch}, Training Metrics: {logs}\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',     # Evaluate every epoch\n",
    "    num_train_epochs=7,              # Number of epochs\n",
    "    per_device_train_batch_size=8,   # Batch size for training\n",
    "    per_device_eval_batch_size=8,    # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps\n",
    "    weight_decay=0.05,               # Strength of weight decay\n",
    "    logging_dir='./logs',            # Directory for logs\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy='epoch',\n",
    ")\n",
    " \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
